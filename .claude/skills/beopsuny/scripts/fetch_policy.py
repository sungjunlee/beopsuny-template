#!/usr/bin/env python3
"""
Korean Policy Stance Fetcher - ì •ë¶€ ì •ì±… ì§‘í–‰ ë™í–¥ ìˆ˜ì§‘

ì •ë¶€ ë¶€ì²˜ ë³´ë„ìë£Œ, í–‰ì •í•´ì„, ì…ë²•ì˜ˆê³  ë“±ì„ ìˆ˜ì§‘í•˜ì—¬
ì •ì±… ì§‘í–‰ ìŠ¤íƒ ìŠ¤ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤.

Usage:
    python fetch_policy.py rss [ë¶€ì²˜ì½”ë“œ] [--keyword í‚¤ì›Œë“œ]
    python fetch_policy.py interpret "ê²€ìƒ‰ì–´" [--display 20]
    python fetch_policy.py legislative [--status ongoing|completed] [--days 30]
    python fetch_policy.py summary [--days 7]
"""

import argparse
import json
import os
import re
import socket
import sys
import urllib.error
import urllib.parse
import urllib.request
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional

try:
    import feedparser
    HAS_FEEDPARSER = True
except ImportError:
    HAS_FEEDPARSER = False

import yaml

# ê²Œì´íŠ¸ì›¨ì´ ìœ í‹¸ë¦¬í‹° (í•´ì™¸ ì ‘ê·¼ ì§€ì›)
try:
    from gateway import fetch_url as gateway_fetch_url, is_gateway_configured, get_geo_status
    HAS_GATEWAY = True
except ImportError:
    HAS_GATEWAY = False

# ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •
SCRIPT_DIR = Path(__file__).parent
SKILL_DIR = SCRIPT_DIR.parent
CONFIG_PATH = SKILL_DIR / "config" / "settings.yaml"
DATA_POLICY_DIR = SKILL_DIR / "data" / "policy"

# í™˜ê²½ë³€ìˆ˜ ì´ë¦„
ENV_OC_CODE = "BEOPSUNY_OC_CODE"
ENV_DATA_GO_KR_KEY = "BEOPSUNY_DATA_GO_KR_KEY"

# ì •ë¶€ ë¶€ì²˜ RSS í”¼ë“œ URL (ì •ì±…ë¸Œë¦¬í•‘ korea.kr)
RSS_FEEDS = {
    "ftc": {
        "name": "ê³µì •ê±°ë˜ìœ„ì›íšŒ",
        "url": "https://korea.kr/rss/dept_ftc.xml",
        "keywords": ["ê³µì •ê±°ë˜", "í•˜ë„ê¸‰", "ê°€ë§¹", "ê³¼ì§•ê¸ˆ", "ì‹œì •ëª…ë ¹", "ë¶ˆê³µì •ê±°ë˜"],
    },
    "moel": {
        "name": "ê³ ìš©ë…¸ë™ë¶€",
        "url": "https://korea.kr/rss/dept_moel.xml",
        "keywords": ["ê·¼ë¡œê¸°ì¤€", "ì‚°ì—…ì•ˆì „", "ì„ê¸ˆ", "í•´ê³ ", "ë…¸ë™", "ê³ ìš©"],
    },
    "fsc": {
        "name": "ê¸ˆìœµìœ„ì›íšŒ",
        "url": "https://korea.kr/rss/dept_fsc.xml",
        "keywords": ["ê¸ˆìœµ", "ì œì¬", "ìë³¸ì‹œì¥", "ê¸ˆìœµì†Œë¹„ì", "ê³¼ì§•ê¸ˆ"],
    },
    "pipc": {
        "name": "ê°œì¸ì •ë³´ë³´í˜¸ìœ„ì›íšŒ",
        "url": "https://korea.kr/rss/dept_pipc.xml",
        "keywords": ["ê°œì¸ì •ë³´", "ê³¼ì§•ê¸ˆ", "ì œì¬", "ì‹œì •ì¡°ì¹˜"],
    },
    "moleg": {
        "name": "ë²•ì œì²˜",
        "url": "https://korea.kr/rss/dept_moleg.xml",
        "keywords": ["ë²•ë ¹", "ì…ë²•", "ë²•ì œ"],
    },
}

# API ì—”ë“œí¬ì¸íŠ¸
API_ENDPOINTS = {
    "moel_interpret": "http://www.law.go.kr/DRF/lawSearch.do",  # ê³ ìš©ë…¸ë™ë¶€ í–‰ì •í•´ì„
    "legislative": "https://opinion.lawmaking.go.kr/rest/ogLmPp",  # ì…ë²•ì˜ˆê³ 
}

# ìºì‹œ
_config_cache = None


def _load_config_file():
    """ì„¤ì • íŒŒì¼ ë¡œë“œ (ìºì‹±)"""
    global _config_cache
    if _config_cache is not None:
        return _config_cache

    if CONFIG_PATH.exists():
        with open(CONFIG_PATH, "r", encoding="utf-8") as f:
            _config_cache = yaml.safe_load(f) or {}
    else:
        _config_cache = {}

    return _config_cache


def get_oc_code() -> str:
    """OC ì½”ë“œ ë¡œë“œ (í™˜ê²½ë³€ìˆ˜ > ì„¤ì •íŒŒì¼)

    Raises:
        ValueError: OC ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
    """
    oc_code = os.environ.get(ENV_OC_CODE)
    if oc_code:
        return oc_code

    config = _load_config_file()
    oc_code = config.get("oc_code", "")

    if not oc_code:
        raise ValueError(
            f"OC code not found. "
            f"Set environment variable {ENV_OC_CODE} or configure in {CONFIG_PATH}"
        )

    return oc_code


def ensure_data_dir():
    """ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±"""
    DATA_POLICY_DIR.mkdir(parents=True, exist_ok=True)


def fetch_url(url: str, timeout: int = 30) -> str:
    """URLì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ê²Œì´íŠ¸ì›¨ì´ ì„¤ì • ì‹œ ìë™ ì‚¬ìš©)

    Args:
        url: ìš”ì²­í•  URL
        timeout: íƒ€ì„ì•„ì›ƒ (ì´ˆ)

    Returns:
        ì‘ë‹µ ë³¸ë¬¸ (UTF-8 ë””ì½”ë”©)

    Raises:
        RuntimeError: ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë°œìƒ ì‹œ
    """
    # ê²Œì´íŠ¸ì›¨ì´ ìœ í‹¸ë¦¬í‹° ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ ìë™ ì²˜ë¦¬
    if HAS_GATEWAY:
        try:
            return gateway_fetch_url(url, timeout=timeout)
        except ValueError as e:
            # ê²Œì´íŠ¸ì›¨ì´ ë¯¸ì„¤ì • ì‹œ ì§ì ‘ ì‹œë„
            print(f"Note: {e}", file=sys.stderr)
            print("Attempting direct connection...", file=sys.stderr)

    # ì§ì ‘ ì ‘ê·¼ (ê²Œì´íŠ¸ì›¨ì´ ë¯¸ì„¤ì •)
    try:
        req = urllib.request.Request(
            url,
            headers={
                "User-Agent": "Mozilla/5.0 (compatible; Beopsuny/1.0; +https://github.com/sungjunlee/beopsuny)"
            },
        )
        with urllib.request.urlopen(req, timeout=timeout) as response:
            return response.read().decode("utf-8")
    except urllib.error.HTTPError as e:
        raise RuntimeError(f"HTTP error {e.code}: {e.reason}") from e
    except urllib.error.URLError as e:
        raise RuntimeError(f"URL error: {e.reason}") from e
    except socket.timeout:
        raise RuntimeError(f"Request timeout after {timeout}s") from None
    except Exception as e:
        raise RuntimeError(f"Unexpected error fetching URL: {e}") from e


# ============================================================
# RSS í”¼ë“œ ìˆ˜ì§‘
# ============================================================


def fetch_rss(
    dept_code: Optional[str] = None,
    keyword: Optional[str] = None,
    limit: int = 20,
) -> List[Dict[str, str]]:
    """RSS í”¼ë“œì—ì„œ ë³´ë„ìë£Œ ìˆ˜ì§‘

    Args:
        dept_code: ë¶€ì²˜ ì½”ë“œ (ftc, moel, fsc, pipc, moleg). Noneì´ë©´ ì „ì²´ ì¡°íšŒ
        keyword: í•„í„°ë§ í‚¤ì›Œë“œ
        limit: ë¶€ì²˜ë‹¹ ìµœëŒ€ ê±´ìˆ˜

    Returns:
        ë³´ë„ìë£Œ ëª©ë¡

    Raises:
        ImportError: feedparser ë¯¸ì„¤ì¹˜ ì‹œ
        ValueError: ì˜ëª»ëœ ë¶€ì²˜ ì½”ë“œ
    """
    if not HAS_FEEDPARSER:
        raise ImportError(
            "feedparser ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì„¤ì¹˜: pip install feedparser"
        )

    # ë¶€ì²˜ ì½”ë“œ ê²€ì¦
    if dept_code:
        if dept_code not in RSS_FEEDS:
            raise ValueError(
                f"ì•Œ ìˆ˜ ì—†ëŠ” ë¶€ì²˜ ì½”ë“œ: {dept_code}. "
                f"ê°€ëŠ¥í•œ ì½”ë“œ: {', '.join(RSS_FEEDS.keys())}"
            )
        feeds_to_check = {dept_code: RSS_FEEDS[dept_code]}
    else:
        feeds_to_check = RSS_FEEDS

    results = []

    for code, feed_info in feeds_to_check.items():
        try:
            feed = feedparser.parse(feed_info["url"])

            # feedparser bozo ì˜¤ë¥˜ ì²´í¬ (íŒŒì‹± ê²½ê³ )
            if hasattr(feed, "bozo") and feed.bozo:
                print(
                    f"Warning: {feed_info['name']} RSS íŒŒì‹± ê²½ê³ : {feed.bozo_exception}",
                    file=sys.stderr,
                )

            if not feed.entries:
                print(
                    f"Warning: {feed_info['name']} RSSì— í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.",
                    file=sys.stderr,
                )
                continue

            for entry in feed.entries[:limit]:
                # í•„ìˆ˜ í•„ë“œ ê²€ì¦
                title = entry.get("title", "")
                if not title:
                    continue

                # í‚¤ì›Œë“œ í•„í„°ë§
                if keyword:
                    title_lower = title.lower()
                    summary_lower = entry.get("summary", "").lower()
                    if keyword.lower() not in title_lower and keyword.lower() not in summary_lower:
                        continue

                results.append({
                    "dept": feed_info["name"],
                    "dept_code": code,
                    "title": title,
                    "link": entry.get("link", ""),
                    "published": entry.get("published", ""),
                    "summary": entry.get("summary", "")[:200] if entry.get("summary") else "",
                })
        except Exception as e:
            print(f"Warning: {feed_info['name']} RSS ìˆ˜ì§‘ ì‹¤íŒ¨: {e}", file=sys.stderr)

    return results


def cmd_rss(args):
    """RSS ë³´ë„ìë£Œ ìˆ˜ì§‘ ëª…ë ¹"""
    is_json = getattr(args, 'format', 'text') == 'json'
    try:
        results = fetch_rss(args.dept, args.keyword, args.limit)
    except ImportError as e:
        if is_json:
            print(json.dumps({'error': str(e), 'results': []}, ensure_ascii=False, indent=2))
        else:
            print(f"Error: {e}", file=sys.stderr)
        sys.exit(1)
    except ValueError as e:
        if is_json:
            print(json.dumps({'error': str(e), 'results': []}, ensure_ascii=False, indent=2))
        else:
            print(f"Error: {e}", file=sys.stderr)
        sys.exit(1)

    if is_json:
        output = {
            'dept': args.dept,
            'keyword': args.keyword,
            'total': len(results),
            'results': results,
        }
        print(json.dumps(output, ensure_ascii=False, indent=2))
        return

    if not results:
        print("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"\nğŸ“° ë³´ë„ìë£Œ ({len(results)}ê±´)")
    print("=" * 60)

    for item in results:
        print(f"\n[{item['dept']}] {item['title']}")
        print(f"  ğŸ“… {item['published']}")
        print(f"  ğŸ”— {item['link']}")
        if item["summary"]:
            print(f"  ğŸ“ {item['summary'][:100]}...")


# ============================================================
# ë²•ë ¹í•´ì„ë¡€ ê²€ìƒ‰ (ë²•ì œì²˜)
# ============================================================


# XML í•„ë“œ ë§¤í•‘ (ì—¬ëŸ¬ API ì‘ë‹µ í˜•ì‹ ì§€ì›)
INTERPRET_FIELD_MAPPINGS = {
    "seq": ["ë²•ë ¹í•´ì„ì¼ë ¨ë²ˆí˜¸", "expcSeq"],
    "title": ["ì•ˆê±´ëª…", "expcNm"],
    "case_no": ["ì•ˆê±´ë²ˆí˜¸", "expcNo"],
    "query_org": ["ì§ˆì˜ê¸°ê´€ëª…", "qryInsttNm"],
    "interpret_org": ["í•´ì„ê¸°ê´€ëª…", "anwInsttNm"],
    "interpret_date": ["í•´ì„ì¼ì", "anwYd"],
}


def _get_xml_field(item: ET.Element, field_key: str) -> str:
    """XML ì•„ì´í…œì—ì„œ ì—¬ëŸ¬ ê°€ëŠ¥í•œ í•„ë“œëª… ì¤‘ ì²« ë²ˆì§¸ ê°’ ë°˜í™˜"""
    for field_name in INTERPRET_FIELD_MAPPINGS.get(field_key, []):
        value = item.findtext(field_name, "")
        if value:
            return value
    return ""


def _is_html_error_response(content: str) -> bool:
    """ì‘ë‹µì´ HTML ì—ëŸ¬ í˜ì´ì§€ì¸ì§€ í™•ì¸"""
    stripped = content.strip()
    return (
        stripped.startswith("<!DOCTYPE")
        or stripped.startswith("<html")
        or stripped.startswith("<HTML")
    )


def search_legal_interpret(
    query: str,
    display: int = 20,
    page: int = 1,
    target: str = "expc",
) -> Dict[str, Any]:
    """ë²•ë ¹í•´ì„ë¡€ ê²€ìƒ‰

    Args:
        query: ê²€ìƒ‰ì–´
        display: í‘œì‹œ ê±´ìˆ˜ (ìµœëŒ€ 100)
        page: í˜ì´ì§€ ë²ˆí˜¸
        target: API íƒ€ê²Ÿ (expc: ì¼ë°˜, moelCgmExpc: ê³ ìš©ë…¸ë™ë¶€)

    Returns:
        ê²€ìƒ‰ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ (total, results, error í‚¤ í¬í•¨)
    """
    try:
        oc = get_oc_code()
    except ValueError as e:
        print(f"Error: {e}", file=sys.stderr)
        return {"total": 0, "results": [], "error": "config_error"}

    params = {
        "OC": oc,
        "target": target,
        "type": "XML",
        "query": query,
        "display": display,
        "page": page,
    }

    url = f"{API_ENDPOINTS['moel_interpret']}?{urllib.parse.urlencode(params)}"

    try:
        content = fetch_url(url)

        # HTML ì—ëŸ¬ í˜ì´ì§€ ê°ì§€ (ì¸ì¦ ì‹¤íŒ¨ ë“±)
        if _is_html_error_response(content):
            print(f"Warning: API ì¸ì¦ ì‹¤íŒ¨ (target={target})", file=sys.stderr)
            print(f"  - ë²•ë ¹í•´ì„ë¡€(expc)ëŠ” ë³„ë„ API ê¶Œí•œì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.", file=sys.stderr)
            print(f"  - https://open.law.go.kr ì—ì„œ ê¶Œí•œ í™•ì¸ ë°”ëë‹ˆë‹¤.", file=sys.stderr)
            return {"total": 0, "results": [], "error": "auth_failed"}

        root = ET.fromstring(content)

        # XML ë‚´ë¶€ ì—ëŸ¬ ë©”ì‹œì§€ í™•ì¸
        error_msg = root.findtext(".//errorMsg") or root.findtext(".//retMsg")
        if error_msg and ("ì¸ì¦" in error_msg or "401" in error_msg):
            print(f"Warning: API ì¸ì¦ ì˜¤ë¥˜: {error_msg}", file=sys.stderr)
            return {"total": 0, "results": [], "error": "auth_failed"}

        results = []
        # expcì™€ moelCgmExpc ë‘ ê°€ì§€ íƒœê·¸ ëª¨ë‘ ì§€ì›
        for tag in ["expc", "moelCgmExpc"]:
            for item in root.findall(f".//{tag}"):
                results.append({
                    "seq": _get_xml_field(item, "seq"),
                    "title": _get_xml_field(item, "title"),
                    "case_no": _get_xml_field(item, "case_no"),
                    "query_org": _get_xml_field(item, "query_org"),
                    "interpret_org": _get_xml_field(item, "interpret_org"),
                    "interpret_date": _get_xml_field(item, "interpret_date"),
                })

        total = root.findtext(".//totalCnt", "0")
        return {"total": int(total), "results": results}

    except RuntimeError as e:
        print(f"Error: ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {e}", file=sys.stderr)
        return {"total": 0, "results": [], "error": "network_error"}
    except ET.ParseError as e:
        print(f"Error: XML íŒŒì‹± ì‹¤íŒ¨: {e}", file=sys.stderr)
        return {"total": 0, "results": [], "error": "parse_error"}
    except Exception as e:
        print(f"Error: ë²•ë ¹í•´ì„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}", file=sys.stderr)
        return {"total": 0, "results": [], "error": str(e)}


def cmd_interpret(args):
    """ë²•ë ¹í•´ì„ë¡€ ê²€ìƒ‰ ëª…ë ¹"""
    is_json = getattr(args, 'format', 'text') == 'json'
    data = search_legal_interpret(args.query, args.display)

    if is_json:
        output = {
            'query': args.query,
            'total': data.get('total', 0),
            'error': data.get('error'),
            'results': data.get('results', []),
        }
        print(json.dumps(output, ensure_ascii=False, indent=2))
        return

    if data.get("error") == "auth_failed":
        print(f"\nâš ï¸  ë²•ë ¹í•´ì„ë¡€ API ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.")
        print(f"    https://open.law.go.kr ì—ì„œ ê¶Œí•œ ì‹ ì²­ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        print(f"\nğŸ’¡ ëŒ€ì•ˆ: ì›¹ê²€ìƒ‰ìœ¼ë¡œ ë²•ë ¹í•´ì„ ì‚¬ë¡€ë¥¼ ì¡°íšŒí•˜ì„¸ìš”:")
        print(f'   ê²€ìƒ‰ì–´: "{args.query} ë²•ë ¹í•´ì„" site:law.go.kr')
        return

    if data["total"] == 0:
        print(f"'{args.query}' ê´€ë ¨ ë²•ë ¹í•´ì„ë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"\nğŸ“‹ ë²•ë ¹í•´ì„ë¡€ (ì´ {data['total']}ê±´ ì¤‘ {len(data['results'])}ê±´)")
    print("=" * 60)

    for item in data["results"]:
        print(f"\nğŸ“Œ {item['title']}")
        print(f"   ì•ˆê±´ë²ˆí˜¸: {item['case_no']}")
        if item['query_org']:
            print(f"   ì§ˆì˜ê¸°ê´€: {item['query_org']}")
        if item['interpret_org']:
            print(f"   í•´ì„ê¸°ê´€: {item['interpret_org']}")
        print(f"   í•´ì„ì¼ì: {item['interpret_date']}")


# ============================================================
# ì…ë²•ì˜ˆê³  ê²€ìƒ‰
# ============================================================


def search_legislative(
    status: str = "ongoing",
    law_name: str = None,
    days: int = 30,
    display: int = 20,
):
    """ì…ë²•ì˜ˆê³  ê²€ìƒ‰"""
    oc = get_oc_code()

    # ë‚ ì§œ ë²”ìœ„ ê³„ì‚°
    end_date = datetime.now()
    start_date = end_date - timedelta(days=days)

    params = {
        "OC": oc,
        "diff": "0" if status == "ongoing" else "1",
        "stYdFmt": start_date.strftime("%Y.%m.%d."),
        "edYdFmt": end_date.strftime("%Y.%m.%d."),
    }

    if law_name:
        params["lsNm"] = law_name

    url = f"{API_ENDPOINTS['legislative']}.xml?{urllib.parse.urlencode(params)}"

    try:
        content = fetch_url(url)

        # 401 ì¸ì¦ ì˜¤ë¥˜ ê°ì§€
        if "<retMsg>401</retMsg>" in content:
            return {"error": "auth_failed", "results": []}

        root = ET.fromstring(content)

        results = []
        # XML êµ¬ì¡°ì— ë”°ë¼ íŒŒì‹± (ì‹¤ì œ ì‘ë‹µ êµ¬ì¡°ì— ë§ê²Œ ì¡°ì • í•„ìš”)
        for item in root.findall(".//ogLmPp"):
            results.append({
                "title": item.findtext("lsNm", ""),
                "ministry": item.findtext("cptOfiNm", ""),
                "notice_no": item.findtext("pntcNo", ""),
                "start_date": item.findtext("stYd", ""),
                "end_date": item.findtext("edYd", ""),
                "status": "ì§„í–‰ì¤‘" if status == "ongoing" else "ì™„ë£Œ",
            })

        return {"results": results[:display]}

    except ET.ParseError:
        # XML íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë¹ˆ ê²°ê³¼ ë°˜í™˜
        print(f"Warning: ì…ë²•ì˜ˆê³  XML íŒŒì‹± ì‹¤íŒ¨", file=sys.stderr)
        return {"error": "parse_error", "results": []}
    except Exception as e:
        print(f"Error: ì…ë²•ì˜ˆê³  ê²€ìƒ‰ ì‹¤íŒ¨: {e}", file=sys.stderr)
        return {"error": str(e), "results": []}


def cmd_legislative(args):
    """ì…ë²•ì˜ˆê³  ê²€ìƒ‰ ëª…ë ¹"""
    is_json = getattr(args, 'format', 'text') == 'json'
    data = search_legislative(
        status=args.status,
        law_name=args.law_name,
        days=args.days,
        display=args.display,
    )

    if is_json:
        output = {
            'status': args.status,
            'law_name': args.law_name,
            'days': args.days,
            'error': data.get('error'),
            'results': data.get('results', []),
        }
        print(json.dumps(output, ensure_ascii=False, indent=2))
        return

    if data.get("error") == "auth_failed":
        print(f"\nâš ï¸  ì…ë²•ì˜ˆê³  API ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.")
        print(f"    êµ­ë¯¼ì°¸ì—¬ì…ë²•ì„¼í„°ì—ì„œ ë³„ë„ ê¶Œí•œ ì‹ ì²­ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        print(f"\nğŸ’¡ ëŒ€ì•ˆ: ì›¹ì‚¬ì´íŠ¸ì—ì„œ ì§ì ‘ í™•ì¸í•˜ì„¸ìš”:")
        print(f"   https://opinion.lawmaking.go.kr (êµ­ë¯¼ì°¸ì—¬ì…ë²•ì„¼í„°)")
        return

    results = data.get("results", [])
    if not results:
        print("ì…ë²•ì˜ˆê³  ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    status_str = "ì§„í–‰ì¤‘" if args.status == "ongoing" else "ì™„ë£Œ"
    print(f"\nğŸ“œ ì…ë²•ì˜ˆê³  ({status_str}, {len(results)}ê±´)")
    print("=" * 60)

    for item in results:
        print(f"\nğŸ“Œ {item['title']}")
        print(f"   ì†Œê´€ë¶€ì²˜: {item['ministry']}")
        print(f"   ì˜ˆê³ ë²ˆí˜¸: {item['notice_no']}")
        print(f"   ì˜ˆê³ ê¸°ê°„: {item['start_date']} ~ {item['end_date']}")


# ============================================================
# ì¢…í•© ìš”ì•½
# ============================================================


def cmd_summary(args):
    """ì •ì±… ë™í–¥ ì¢…í•© ìš”ì•½"""
    print("\n" + "=" * 60)
    print("ğŸ“Š ì •ë¶€ ì •ì±… ì§‘í–‰ ë™í–¥ ìš”ì•½")
    print("=" * 60)

    # 1. RSS ë³´ë„ìë£Œ (ì œì¬ ê´€ë ¨)
    print("\n\n## 1. ìµœê·¼ ë³´ë„ìë£Œ (ì œì¬/ì •ì±… ê´€ë ¨)")
    print("-" * 40)

    enforcement_keywords = ["ì œì¬", "ê³¼ì§•ê¸ˆ", "ì‹œì •ëª…ë ¹", "ì‹œì •ì¡°ì¹˜", "ìœ„ë°˜", "ì²˜ë¶„"]

    for dept_code, feed_info in RSS_FEEDS.items():
        if dept_code in ["ftc", "moel", "fsc", "pipc"]:  # ì£¼ìš” ë¶€ì²˜ë§Œ
            try:
                if HAS_FEEDPARSER:
                    results = fetch_rss(dept_code, limit=5)
                    relevant = [r for r in results if any(kw in r["title"] for kw in enforcement_keywords)]
                    if relevant:
                        print(f"\n### {feed_info['name']}")
                        for item in relevant[:3]:
                            print(f"  - {item['title'][:50]}...")
                            print(f"    {item['link']}")
            except Exception:
                pass

    # 2. ë²•ë ¹í•´ì„ë¡€ (ìµœê·¼)
    print("\n\n## 2. ìµœê·¼ ì£¼ìš” ë²•ë ¹í•´ì„ë¡€")
    print("-" * 40)

    for keyword in ["í•´ê³ ", "ì„ê¸ˆ", "ê·¼ë¡œì‹œê°„"]:
        try:
            data = search_legal_interpret(keyword, display=3)
            if data.get("error") == "auth_failed":
                print(f"\n  âš ï¸ ë²•ë ¹í•´ì„ë¡€ API ê¶Œí•œ ì—†ìŒ")
                print(f"     ì›¹ê²€ìƒ‰ ëŒ€ì•ˆ: \"{keyword} ë²•ë ¹í•´ì„\" site:law.go.kr")
                break
            if data["results"]:
                print(f"\n### '{keyword}' ê´€ë ¨")
                for item in data["results"][:2]:
                    print(f"  - {item['title'][:50]}...")
        except Exception:
            pass

    # 3. ì…ë²•ì˜ˆê³ 
    print("\n\n## 3. ì§„í–‰ì¤‘ì¸ ì…ë²•ì˜ˆê³ ")
    print("-" * 40)

    try:
        data = search_legislative(status="ongoing", days=args.days, display=10)
        if data.get("error") == "auth_failed":
            print(f"  âš ï¸ ì…ë²•ì˜ˆê³  API ê¶Œí•œ ì—†ìŒ")
            print(f"     ëŒ€ì•ˆ: https://opinion.lawmaking.go.kr")
        elif data.get("results"):
            for item in data["results"][:5]:
                print(f"  - [{item['ministry']}] {item['title'][:40]}...")
                print(f"    ì˜ˆê³ ê¸°ê°„: {item['start_date']} ~ {item['end_date']}")
        else:
            print("  (ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ)")
    except Exception:
        print("  (ê²€ìƒ‰ ì‹¤íŒ¨)")

    print("\n" + "=" * 60)
    print("ğŸ’¡ ìƒì„¸ ì •ë³´ëŠ” ê°œë³„ ëª…ë ¹ìœ¼ë¡œ í™•ì¸í•˜ì„¸ìš”:")
    print("   python fetch_policy.py rss ftc --keyword ê³¼ì§•ê¸ˆ")
    print("   python fetch_policy.py interpret í•´ê³ ")
    print("   python fetch_policy.py legislative --status ongoing")


# ============================================================
# ê²Œì´íŠ¸ì›¨ì´ ìƒíƒœ í™•ì¸
# ============================================================


def cmd_gateway_status():
    """ê²Œì´íŠ¸ì›¨ì´ ìƒíƒœ í™•ì¸ ëª…ë ¹"""
    if not HAS_GATEWAY:
        print("âš ï¸  gateway.pyë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   ê°™ì€ ë””ë ‰í† ë¦¬ì— gateway.pyê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return

    status = get_geo_status()

    print("\n" + "=" * 50)
    print("ğŸŒ ê²Œì´íŠ¸ì›¨ì´ ìƒíƒœ í™•ì¸")
    print("=" * 50)

    print(f"\nâš™ï¸  ê²Œì´íŠ¸ì›¨ì´ ì„¤ì •")
    print(f"   ì„¤ì •ë¨: {'ì˜ˆ' if status['gateway_configured'] else 'ì•„ë‹ˆì˜¤'}")
    if status['gateway_configured']:
        print(f"   URL: {status['gateway_url']}")
        print(f"   API í‚¤: {'ì„¤ì •ë¨' if status['has_api_key'] else 'ì—†ìŒ'}")

    if not status['gateway_configured']:
        print("\n" + "-" * 50)
        print("âš ï¸  ê²Œì´íŠ¸ì›¨ì´ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   í•´ì™¸ì—ì„œ í•œêµ­ ì •ë¶€ API ì ‘ê·¼ì´ ì°¨ë‹¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("\nğŸ“‹ ì„¤ì • ë°©ë²•:")
        print("   export BEOPSUNY_GATEWAY_URL='https://your-gateway.example.com'")
        print("   export BEOPSUNY_GATEWAY_API_KEY='your-api-key'  # ì„ íƒ")
    else:
        print("\nâœ… ê²Œì´íŠ¸ì›¨ì´ ì„¤ì • ì™„ë£Œ")


# ============================================================
# CLI
# ============================================================


def main():
    parser = argparse.ArgumentParser(
        description="ì •ë¶€ ì •ì±… ì§‘í–‰ ë™í–¥ ìˆ˜ì§‘",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # RSS ë³´ë„ìë£Œ ìˆ˜ì§‘
  python fetch_policy.py rss                    # ì „ì²´ ë¶€ì²˜
  python fetch_policy.py rss ftc                # ê³µì •ê±°ë˜ìœ„ì›íšŒë§Œ
  python fetch_policy.py rss ftc --keyword ê³¼ì§•ê¸ˆ

  # ê³ ìš©ë…¸ë™ë¶€ í–‰ì •í•´ì„ ê²€ìƒ‰
  python fetch_policy.py interpret "í•´ê³ "
  python fetch_policy.py interpret "ì„ê¸ˆ" --display 30

  # ì…ë²•ì˜ˆê³  ê²€ìƒ‰
  python fetch_policy.py legislative --status ongoing
  python fetch_policy.py legislative --law-name "ê·¼ë¡œê¸°ì¤€ë²•"

  # ì¢…í•© ìš”ì•½
  python fetch_policy.py summary --days 7

Available dept codes: ftc, moel, fsc, pipc, moleg
        """,
    )

    subparsers = parser.add_subparsers(dest="command", help="ëª…ë ¹")

    # rss ëª…ë ¹
    rss_parser = subparsers.add_parser("rss", help="RSS ë³´ë„ìë£Œ ìˆ˜ì§‘")
    rss_parser.add_argument("dept", nargs="?", help="ë¶€ì²˜ ì½”ë“œ (ftc, moel, fsc, pipc, moleg)")
    rss_parser.add_argument("--keyword", "-k", help="í‚¤ì›Œë“œ í•„í„°")
    rss_parser.add_argument("--limit", "-l", type=int, default=20, help="ìµœëŒ€ ê±´ìˆ˜ (ê¸°ë³¸: 20)")
    rss_parser.add_argument("--format", "-f", default="text", choices=["text", "json"],
                            help="ì¶œë ¥ í˜•ì‹ (text: í…ìŠ¤íŠ¸, json: JSON)")

    # interpret ëª…ë ¹
    interpret_parser = subparsers.add_parser("interpret", help="ê³ ìš©ë…¸ë™ë¶€ í–‰ì •í•´ì„ ê²€ìƒ‰")
    interpret_parser.add_argument("query", help="ê²€ìƒ‰ì–´")
    interpret_parser.add_argument("--display", "-d", type=int, default=20, help="í‘œì‹œ ê±´ìˆ˜")
    interpret_parser.add_argument("--format", "-f", default="text", choices=["text", "json"],
                                  help="ì¶œë ¥ í˜•ì‹ (text: í…ìŠ¤íŠ¸, json: JSON)")

    # legislative ëª…ë ¹
    leg_parser = subparsers.add_parser("legislative", help="ì…ë²•ì˜ˆê³  ê²€ìƒ‰")
    leg_parser.add_argument("--status", "-s", choices=["ongoing", "completed"], default="ongoing", help="ìƒíƒœ")
    leg_parser.add_argument("--law-name", "-n", help="ë²•ë ¹ëª…")
    leg_parser.add_argument("--days", "-d", type=int, default=30, help="ê²€ìƒ‰ ê¸°ê°„ (ì¼)")
    leg_parser.add_argument("--display", type=int, default=20, help="í‘œì‹œ ê±´ìˆ˜")
    leg_parser.add_argument("--format", "-f", default="text", choices=["text", "json"],
                            help="ì¶œë ¥ í˜•ì‹ (text: í…ìŠ¤íŠ¸, json: JSON)")

    # summary ëª…ë ¹
    summary_parser = subparsers.add_parser("summary", help="ì •ì±… ë™í–¥ ì¢…í•© ìš”ì•½")
    summary_parser.add_argument("--days", "-d", type=int, default=7, help="ê²€ìƒ‰ ê¸°ê°„ (ì¼)")

    # gateway-status ëª…ë ¹
    gateway_parser = subparsers.add_parser("gateway-status", help="ê²Œì´íŠ¸ì›¨ì´ ìƒíƒœ í™•ì¸")

    args = parser.parse_args()

    # ê²Œì´íŠ¸ì›¨ì´ ìƒíƒœ ëª…ë ¹
    if args.command == "gateway-status":
        cmd_gateway_status()
        return

    if args.command == "rss":
        cmd_rss(args)
    elif args.command == "interpret":
        cmd_interpret(args)
    elif args.command == "legislative":
        cmd_legislative(args)
    elif args.command == "summary":
        cmd_summary(args)
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
