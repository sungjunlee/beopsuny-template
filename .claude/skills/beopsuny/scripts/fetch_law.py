#!/usr/bin/env python3
"""
Korean Law Fetcher - êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„° API í´ë¼ì´ì–¸íŠ¸

Usage:
    python fetch_law.py search "ê²€ìƒ‰ì–´" [--type law|prec|ordin|admrul|expc|detc]
    python fetch_law.py cases "ê²€ìƒ‰ì–´" [--court ëŒ€ë²•ì›|ê³ ë“±|ì§€ë°©] [--from YYYYMMDD]
    python fetch_law.py fetch --id ë²•ë ¹ID [--with-decree]
    python fetch_law.py fetch --name "ë²•ë ¹ëª…" [--with-decree]
    python fetch_law.py recent [--days 30] [--from YYYYMMDD] [--to YYYYMMDD]
    python fetch_law.py checklist list
    python fetch_law.py checklist show <name> [--output FILE]
"""

import argparse
import calendar
import json
import os
import re
import sys
import urllib.parse
import urllib.request
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
from pathlib import Path

import yaml

# ê²Œì´íŠ¸ì›¨ì´ ìœ í‹¸ë¦¬í‹° (í•´ì™¸ ì ‘ê·¼ ì§€ì›)
try:
    from gateway import fetch_url, is_gateway_configured
    HAS_GATEWAY = True
except ImportError:
    HAS_GATEWAY = False

# ì¤‘ì•™í™”ëœ ê²½ë¡œ ìƒìˆ˜ ì‚¬ìš© (common/paths.py)
from common.paths import (
    CONFIG_PATH,
    LAW_INDEX_PATH,
    CHECKLISTS_DIR,
    CALENDAR_PATH,
    DATA_RAW_DIR,
    DATA_PARSED_DIR,
    API_BASE_URL,
)

# API ê¸°ë³¸ URL (common/paths.pyì—ì„œ ê°€ì ¸ì˜´)
BASE_URL = API_BASE_URL

# í™˜ê²½ë³€ìˆ˜ ì´ë¦„
ENV_OC_CODE = "BEOPSUNY_OC_CODE"

# ê²€ìƒ‰ ëŒ€ìƒ íƒ€ì… í‘œì‹œëª…
TARGET_TYPE_NAMES = {
    'law': 'ë²•ë ¹',
    'prec': 'íŒë¡€',
    'ordin': 'ìì¹˜ë²•ê·œ',
    'admrul': 'í–‰ì •ê·œì¹™',
    'expc': 'ë²•ë ¹í•´ì„ë¡€',
    'detc': 'í—Œì¬ê²°ì •ë¡€',
}

# ìì¹˜ë²•ê·œ ì¢…ë¥˜ ì½”ë“œ ë§¤í•‘
ORDIN_TYPE_MAP = {
    'C0001': 'ì¡°ë¡€',
    'C0002': 'ê·œì¹™',
}

# ìºì‹œ
_config_cache = None
_law_index_cache = None


def _sanitize_filename(name: str) -> str:
    """íŒŒì¼ëª…ì—ì„œ íŠ¹ìˆ˜ë¬¸ì ì œê±°

    Returns:
        ì•ˆì „í•œ íŒŒì¼ëª… (ë¹ˆ ë¬¸ìì—´ì¸ ê²½ìš° 'unnamed' ë°˜í™˜)
    """
    cleaned = "".join(c for c in name if c.isalnum() or c in (' ', '_', '-')).strip()
    return cleaned or 'unnamed'


def _clean_html_text(text: str, preserve_breaks: bool = False, max_length: int = None) -> str:
    """HTML íƒœê·¸ ì œê±° ë° í…ìŠ¤íŠ¸ ì •ë¦¬

    Args:
        text: HTMLì´ í¬í•¨ëœ í…ìŠ¤íŠ¸
        preserve_breaks: <br> íƒœê·¸ë¥¼ ì¤„ë°”ê¿ˆìœ¼ë¡œ ë³€í™˜í• ì§€ ì—¬ë¶€
        max_length: ìµœëŒ€ ê¸¸ì´ (ì´ˆê³¼ì‹œ ... ì¶”ê°€)
    """
    if preserve_breaks:
        text = re.sub(r'<br\s*/?>', '\n', text)
    text = re.sub(r'<[^>]+>', '', text)
    text = text.strip()

    if max_length and len(text) > max_length:
        return text[:max_length] + "..."
    return text


def _load_config_file():
    """ì„¤ì • íŒŒì¼ ë¡œë“œ (ìºì‹±)"""
    global _config_cache
    if _config_cache is not None:
        return _config_cache

    if CONFIG_PATH.exists():
        with open(CONFIG_PATH, 'r', encoding='utf-8') as f:
            _config_cache = yaml.safe_load(f) or {}
    else:
        _config_cache = {}

    return _config_cache


def _load_law_index():
    """ë²•ë ¹ ì¸ë±ìŠ¤ íŒŒì¼ ë¡œë“œ (ìºì‹±)"""
    global _law_index_cache
    if _law_index_cache is not None:
        return _law_index_cache

    if LAW_INDEX_PATH.exists():
        with open(LAW_INDEX_PATH, 'r', encoding='utf-8') as f:
            _law_index_cache = yaml.safe_load(f) or {}
    else:
        _law_index_cache = {}

    return _law_index_cache


def load_config():
    """OC ì½”ë“œ ë¡œë“œ (í™˜ê²½ë³€ìˆ˜ > ì„¤ì •íŒŒì¼)"""
    # 1. í™˜ê²½ë³€ìˆ˜ ìš°ì„ 
    oc_code = os.environ.get(ENV_OC_CODE)
    if oc_code:
        return oc_code

    # 2. ì„¤ì • íŒŒì¼ fallback
    config = _load_config_file()
    oc_code = config.get('oc_code', '')

    if not oc_code:
        print(f"Error: OC code not found.", file=sys.stderr)
        print(f"", file=sys.stderr)
        print(f"Set one of the following:", file=sys.stderr)
        print(f"  1. Environment variable: export {ENV_OC_CODE}=your_oc_code", file=sys.stderr)
        print(f"  2. Config file: {CONFIG_PATH}", file=sys.stderr)
        print(f"", file=sys.stderr)
        print(f"Get your OC code at: https://open.law.go.kr", file=sys.stderr)
        sys.exit(1)

    return oc_code


def get_major_law_id(name: str) -> str | None:
    """ì£¼ìš” ë²•ë ¹ì˜ IDë¥¼ law_index.yamlì—ì„œ ì¡°íšŒ"""
    law_index = _load_law_index()
    major_laws = law_index.get('major_laws', {})

    # ì •í™•í•œ ì´ë¦„ìœ¼ë¡œ ë¨¼ì € ê²€ìƒ‰
    if name in major_laws:
        return major_laws[name]

    # ê³µë°± ì œê±° í›„ ê²€ìƒ‰
    clean_name = name.replace(' ', '')
    for law_name, law_id in major_laws.items():
        if law_name.replace(' ', '') == clean_name:
            return law_id

    return None


def api_request(endpoint: str, params: dict) -> ET.Element:
    """API ìš”ì²­ ë° XML íŒŒì‹± (ê²Œì´íŠ¸ì›¨ì´ ìë™ ì‚¬ìš©)"""
    url = f"{BASE_URL}/{endpoint}?{urllib.parse.urlencode(params)}"

    try:
        # ê²Œì´íŠ¸ì›¨ì´ ìœ í‹¸ë¦¬í‹° ì‚¬ìš© (ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ìë™ ì‚¬ìš©)
        if HAS_GATEWAY:
            try:
                content = fetch_url(url, timeout=30)
            except ValueError as e:
                # ê²Œì´íŠ¸ì›¨ì´ ë¯¸ì„¤ì • ì‹œ ì§ì ‘ ì‹œë„
                print(f"Note: {e}", file=sys.stderr)
                print("Attempting direct connection...", file=sys.stderr)
                content = None

            if content is not None:
                # HTML ì‘ë‹µ ê°ì§€
                if content.strip().startswith('<!DOCTYPE') or content.strip().startswith('<html'):
                    print(f"Error: API returned HTML instead of XML.", file=sys.stderr)
                    print(f"This usually means overseas access is blocked.", file=sys.stderr)
                    print(f"", file=sys.stderr)
                    print(f"Solution: Configure cors-anywhere gateway:", file=sys.stderr)
                    print(f"  export BEOPSUNY_GATEWAY_URL='https://your-gateway.example.com'", file=sys.stderr)
                    sys.exit(1)

                return ET.fromstring(content)

        # ì§ì ‘ ì ‘ê·¼ (ê²Œì´íŠ¸ì›¨ì´ ë¯¸ì„¤ì •)
        req = urllib.request.Request(url, headers={"User-Agent": "Mozilla/5.0"})
        with urllib.request.urlopen(req, timeout=30) as response:
            content = response.read().decode('utf-8')

            # HTML ì‘ë‹µ ê°ì§€ (API ì˜¤ë¥˜ ì‹œ HTML ë°˜í™˜ë¨)
            if content.strip().startswith('<!DOCTYPE') or content.strip().startswith('<html'):
                print(f"Error: API returned HTML instead of XML.", file=sys.stderr)
                print(f"This usually means overseas access is blocked.", file=sys.stderr)
                print(f"", file=sys.stderr)
                print(f"Solution: Configure cors-anywhere gateway:", file=sys.stderr)
                print(f"  export BEOPSUNY_GATEWAY_URL='https://your-gateway.example.com'", file=sys.stderr)
                print(f"", file=sys.stderr)
                print(f"URL: {url}", file=sys.stderr)
                sys.exit(1)

            return ET.fromstring(content)
    except urllib.error.HTTPError as e:
        print(f"Error: HTTP {e.code} - {e.reason}", file=sys.stderr)
        if e.code == 403:
            print(f"", file=sys.stderr)
            print(f"403 Forbidden - overseas access may be blocked.", file=sys.stderr)
            print(f"Configure gateway: export BEOPSUNY_GATEWAY_URL='https://...'", file=sys.stderr)
        sys.exit(1)
    except urllib.error.URLError as e:
        print(f"Error: API request failed - {e}", file=sys.stderr)
        sys.exit(1)
    except ET.ParseError as e:
        print(f"Error: Failed to parse XML response - {e}", file=sys.stderr)
        print(f"", file=sys.stderr)
        print(f"This may indicate the API returned an error page instead of XML.", file=sys.stderr)
        print(f"URL: {url}", file=sys.stderr)
        sys.exit(1)


def search_laws(query: str, target: str = "law", display: int = 20, page: int = 1, sort: str = None, output_format: str = "text"):
    """
    ë²•ë ¹ ê²€ìƒ‰

    Args:
        query: ê²€ìƒ‰ì–´
        target: ê²€ìƒ‰ ëŒ€ìƒ (law: ë²•ë ¹, prec: íŒë¡€, ordin: ìì¹˜ë²•ê·œ, admrul: í–‰ì •ê·œì¹™, expc: ë²•ë ¹í•´ì„ë¡€, detc: í—Œì¬ê²°ì •ë¡€)
        display: ê²°ê³¼ ê°œìˆ˜ (ìµœëŒ€ 100)
        page: í˜ì´ì§€ ë²ˆí˜¸
        sort: ì •ë ¬ ê¸°ì¤€ (date: ë‚ ì§œìˆœ, name: ì´ë¦„ìˆœ)
        output_format: ì¶œë ¥ í˜•ì‹ (text: í…ìŠ¤íŠ¸, json: JSON)
    """
    oc = load_config()

    params = {
        'OC': oc,
        'target': target,
        'type': 'XML',
        'query': query,
        'display': display,
        'page': page,
    }

    if sort:
        params['sort'] = sort

    root = api_request('lawSearch.do', params)

    # ê²°ê³¼ íŒŒì‹± - targetì— ë”°ë¼ ë‹¤ë¥¸ íƒœê·¸ ì‚¬ìš©
    total = root.findtext('.//totalCnt', '0')

    target_name = TARGET_TYPE_NAMES.get(target, target)

    # JSON ì¶œë ¥ ëª¨ë“œì—ì„œëŠ” í…ìŠ¤íŠ¸ ì¶œë ¥ ìƒëµ
    is_json = output_format == 'json'
    if not is_json:
        print(f"\n=== {target_name} ê²€ìƒ‰ ê²°ê³¼: '{query}' (ì´ {total}ê±´) ===\n")

    results = []

    # íŒë¡€ ê²€ìƒ‰
    if target == 'prec':
        for item in root.findall('.//prec'):
            case_id = item.findtext('íŒë¡€ì¼ë ¨ë²ˆí˜¸', '')
            case_name = item.findtext('ì‚¬ê±´ëª…', '')
            case_number = item.findtext('ì‚¬ê±´ë²ˆí˜¸', '')
            court_name = item.findtext('ë²•ì›ëª…', '')
            judge_date = item.findtext('ì„ ê³ ì¼ì', '')
            case_type = item.findtext('ì‚¬ê±´ì¢…ë¥˜ëª…', '')

            results.append({
                'id': case_id,
                'name': case_name,
                'case_number': case_number,
                'court': court_name,
                'judge_date': judge_date,
                'type': case_type,
            })

            if not is_json:
                print(f"âš–ï¸  {case_name}")
                print(f"   ì‚¬ê±´ë²ˆí˜¸: {case_number}")
                print(f"   ë²•ì›: {court_name} | ì„ ê³ ì¼: {judge_date}")
                print(f"   ì‚¬ê±´ì¢…ë¥˜: {case_type}")
                print(f"   ë§í¬: https://www.law.go.kr/íŒë¡€/({case_number.replace(' ', '')})")
                print()

    # í–‰ì •ê·œì¹™ ê²€ìƒ‰
    elif target == 'admrul':
        for item in root.findall('.//admrul'):
            admrul_id = item.findtext('í–‰ì •ê·œì¹™ì¼ë ¨ë²ˆí˜¸', '')
            admrul_name = item.findtext('í–‰ì •ê·œì¹™ëª…', '')
            admrul_type = item.findtext('í–‰ì •ê·œì¹™ì¢…ë¥˜', '')
            promul_date = item.findtext('ë°œë ¹ì¼ì', '')
            enforce_date = item.findtext('ì‹œí–‰ì¼ì', '')
            ministry = item.findtext('ì†Œê´€ë¶€ì²˜ëª…', '')

            results.append({
                'id': admrul_id,
                'name': admrul_name,
                'type': admrul_type,
                'promul_date': promul_date,
                'enforce_date': enforce_date,
                'ministry': ministry,
            })

            if not is_json:
                print(f"ğŸ“‹ [{admrul_type}] {admrul_name}")
                print(f"   ID: {admrul_id}")
                print(f"   ì†Œê´€: {ministry}")
                print(f"   ë°œë ¹ì¼: {promul_date} | ì‹œí–‰ì¼: {enforce_date}")
                print(f"   ë§í¬: https://www.law.go.kr/í–‰ì •ê·œì¹™/{urllib.parse.quote(admrul_name)}")
                print()

    # ìì¹˜ë²•ê·œ ê²€ìƒ‰
    elif target == 'ordin':
        for item in root.findall('.//law'):
            ordin_id = item.findtext('ìì¹˜ë²•ê·œì¼ë ¨ë²ˆí˜¸', '') or item.findtext('ìì¹˜ë²•ê·œID', '')
            ordin_name = item.findtext('ìì¹˜ë²•ê·œëª…', '')
            ordin_type = item.findtext('ìì¹˜ë²•ê·œì¢…ë¥˜', '')
            local_gov = item.findtext('ì§€ìì²´ê¸°ê´€ëª…', '')
            promul_date = item.findtext('ê³µí¬ì¼ì', '')
            enforce_date = item.findtext('ì‹œí–‰ì¼ì', '')

            results.append({
                'id': ordin_id,
                'name': ordin_name,
                'type': ordin_type,
                'local_gov': local_gov,
                'promul_date': promul_date,
                'enforce_date': enforce_date,
            })

            if not is_json:
                print(f"ğŸ›ï¸  [{ordin_type}] {ordin_name}")
                print(f"   ID: {ordin_id}")
                print(f"   ì§€ìì²´: {local_gov}")
                print(f"   ê³µí¬ì¼: {promul_date} | ì‹œí–‰ì¼: {enforce_date}")
                print(f"   ë§í¬: https://www.law.go.kr/ìì¹˜ë²•ê·œ/{urllib.parse.quote(ordin_name)}")
                print()

    # ë²•ë ¹í•´ì„ë¡€ ê²€ìƒ‰
    elif target == 'expc':
        for item in root.findall('.//expc'):
            expc_id = item.findtext('ë²•ë ¹í•´ì„ë¡€ì¼ë ¨ë²ˆí˜¸', '')
            case_name = item.findtext('ì•ˆê±´ëª…', '')
            case_number = item.findtext('ì•ˆê±´ë²ˆí˜¸', '')
            request_org = item.findtext('ì§ˆì˜ê¸°ê´€ëª…', '')
            response_org = item.findtext('íšŒì‹ ê¸°ê´€ëª…', '')
            response_date = item.findtext('íšŒì‹ ì¼ì', '')

            results.append({
                'id': expc_id,
                'name': case_name,
                'case_number': case_number,
                'request_org': request_org,
                'response_org': response_org,
                'response_date': response_date,
            })

            if not is_json:
                print(f"ğŸ“ {case_name}")
                print(f"   ì•ˆê±´ë²ˆí˜¸: {case_number}")
                print(f"   ì§ˆì˜ê¸°ê´€: {request_org} â†’ íšŒì‹ ê¸°ê´€: {response_org}")
                print(f"   íšŒì‹ ì¼: {response_date}")
                print()

    # í—Œì¬ê²°ì •ë¡€ ê²€ìƒ‰
    elif target == 'detc':
        for item in root.findall('.//Detc'):
            detc_id = item.findtext('í—Œì¬ê²°ì •ë¡€ì¼ë ¨ë²ˆí˜¸', '')
            case_name = item.findtext('ì‚¬ê±´ëª…', '')
            case_number = item.findtext('ì‚¬ê±´ë²ˆí˜¸', '')
            decision_date = item.findtext('ì¢…êµ­ì¼ì', '')
            decision_type = item.findtext('ê²°ì •ìœ í˜•', '')
            case_type = item.findtext('ì‚¬ê±´ì¢…ë¥˜', '')

            results.append({
                'id': detc_id,
                'name': case_name,
                'case_number': case_number,
                'decision_date': decision_date,
                'decision_type': decision_type,
                'case_type': case_type,
            })

            if not is_json:
                print(f"âš–ï¸  {case_name}")
                print(f"   ì‚¬ê±´ë²ˆí˜¸: {case_number}")
                print(f"   ì¢…êµ­ì¼: {decision_date}")
                if decision_type:
                    print(f"   ê²°ì •ìœ í˜•: {decision_type}")
                print(f"   ë§í¬: https://www.law.go.kr/í—Œì¬ê²°ì •ë¡€/({case_number.replace(' ', '')})")
                print()

    # ë²•ë ¹ ê²€ìƒ‰ (ê¸°ë³¸)
    else:
        for item in root.findall('.//law'):
            law_id = item.findtext('ë²•ë ¹ID', '')
            law_name = item.findtext('ë²•ë ¹ëª…í•œê¸€', '') or item.findtext('ë²•ë ¹ëª…', '')
            promul_date = item.findtext('ê³µí¬ì¼ì', '')
            enforce_date = item.findtext('ì‹œí–‰ì¼ì', '')
            ministry = item.findtext('ì†Œê´€ë¶€ì²˜ëª…', '')
            law_type = item.findtext('ë²•ë ¹êµ¬ë¶„ëª…', '')

            results.append({
                'id': law_id,
                'name': law_name,
                'promul_date': promul_date,
                'enforce_date': enforce_date,
                'ministry': ministry,
                'type': law_type,
            })

            if not is_json:
                print(f"ğŸ“œ {law_name}")
                print(f"   ID: {law_id}")
                print(f"   êµ¬ë¶„: {law_type} | ì†Œê´€: {ministry}")
                print(f"   ê³µí¬ì¼: {promul_date} | ì‹œí–‰ì¼: {enforce_date}")
                print(f"   ë§í¬: https://www.law.go.kr/ë²•ë ¹/{urllib.parse.quote(law_name)}")
                print()

    # JSON ì¶œë ¥
    if is_json:
        output = {
            'query': query,
            'target': target,
            'total': int(total),
            'page': page,
            'display': display,
            'results': results,
        }
        print(json.dumps(output, ensure_ascii=False, indent=2))

    return results


def search_cases(query: str, court: str = None, from_date: str = None, display: int = 20, page: int = 1, output_format: str = "text"):
    """
    íŒë¡€ ì „ìš© ê²€ìƒ‰

    Args:
        query: ê²€ìƒ‰ì–´
        court: ë²•ì› í•„í„° (ëŒ€ë²•ì›, ê³ ë“±, ì§€ë°© ë“±)
        from_date: ê²€ìƒ‰ ì‹œì‘ì¼ (YYYYMMDD)
        display: ê²°ê³¼ ê°œìˆ˜
        page: í˜ì´ì§€ ë²ˆí˜¸
        output_format: ì¶œë ¥ í˜•ì‹ (text: í…ìŠ¤íŠ¸, json: JSON)
    """
    oc = load_config()

    params = {
        'OC': oc,
        'target': 'prec',
        'type': 'XML',
        'query': query,
        'display': display,
        'page': page,
    }

    # ë‚ ì§œ í•„í„° (ì„ ê³ ì¼ ê¸°ì¤€)
    if from_date:
        params['sort'] = 'date'

    root = api_request('lawSearch.do', params)

    total = root.findtext('.//totalCnt', '0')
    is_json = output_format == 'json'
    if not is_json:
        print(f"\n=== íŒë¡€ ê²€ìƒ‰ ê²°ê³¼: '{query}' (ì´ {total}ê±´) ===\n")

    results = []
    for item in root.findall('.//prec'):
        case_id = item.findtext('íŒë¡€ì¼ë ¨ë²ˆí˜¸', '')
        case_name = item.findtext('ì‚¬ê±´ëª…', '')
        case_number = item.findtext('ì‚¬ê±´ë²ˆí˜¸', '')
        court_name = item.findtext('ë²•ì›ëª…', '')
        judge_date = item.findtext('ì„ ê³ ì¼ì', '')
        case_type = item.findtext('ì‚¬ê±´ì¢…ë¥˜ëª…', '')
        judgment_type = item.findtext('íŒê²°ìœ í˜•', '')

        # ë²•ì› í•„í„°ë§
        if court and court not in court_name:
            continue

        # ë‚ ì§œ í•„í„°ë§
        if from_date and judge_date and judge_date < from_date:
            continue

        results.append({
            'id': case_id,
            'name': case_name,
            'case_number': case_number,
            'court': court_name,
            'judge_date': judge_date,
            'type': case_type,
            'judgment_type': judgment_type,
        })

        if not is_json:
            # íŒë¡€ ì¸ìš© í˜•ì‹ìœ¼ë¡œ ì¶œë ¥
            formatted_date = format_court_date(judge_date) if judge_date else ''
            print(f"âš–ï¸  {court_name} {formatted_date} ì„ ê³  {case_number} íŒê²°")
            print(f"   ì‚¬ê±´ëª…: {case_name}")
            print(f"   ì‚¬ê±´ì¢…ë¥˜: {case_type}")
            print(f"   ë§í¬: https://www.law.go.kr/íŒë¡€/({case_number.replace(' ', '')})")
            print()

    if is_json:
        output = {
            'query': query,
            'total': int(total),
            'page': page,
            'display': display,
            'court_filter': court,
            'from_date': from_date,
            'results': results,
        }
        print(json.dumps(output, ensure_ascii=False, indent=2))
    else:
        print(f"ì´ {len(results)}ê±´")

    return results


def format_court_date(date_str: str) -> str:
    """ì„ ê³ ì¼ì í¬ë§·íŒ… (20230112 â†’ 2023. 1. 12.)"""
    if len(date_str) == 8:
        year = date_str[:4]
        month = str(int(date_str[4:6]))
        day = str(int(date_str[6:8]))
        return f"{year}. {month}. {day}."
    return date_str


def find_cached_law(law_id: str = None, law_name: str = None) -> Path | None:
    """
    ìºì‹œëœ ë²•ë ¹ íŒŒì¼ ì°¾ê¸°

    Args:
        law_id: ë²•ë ¹ ID
        law_name: ë²•ë ¹ëª…

    Returns:
        ìºì‹œëœ íŒŒì¼ ê²½ë¡œ ë˜ëŠ” None
    """
    if not DATA_RAW_DIR.exists():
        return None

    for filepath in DATA_RAW_DIR.glob("*.xml"):
        if law_id and law_id in filepath.name:
            return filepath
        if law_name:
            safe_name = _sanitize_filename(law_name)
            if safe_name in filepath.name:
                return filepath
    return None


def fetch_law_by_id(law_id: str, save: bool = True, force: bool = False, target: str = "law"):
    """
    ë²•ë ¹/í–‰ì •ê·œì¹™ ë“± IDë¡œ ë³¸ë¬¸ ì¡°íšŒ

    Args:
        law_id: ë²•ë ¹/í–‰ì •ê·œì¹™ ì¼ë ¨ë²ˆí˜¸
        save: íŒŒì¼ë¡œ ì €ì¥ ì—¬ë¶€
        force: ìºì‹œ ë¬´ì‹œí•˜ê³  ê°•ì œ ë‹¤ìš´ë¡œë“œ
        target: ê²€ìƒ‰ ëŒ€ìƒ (law, admrul, prec, ordin, expc, detc)
    """
    # ìºì‹œ í™•ì¸ (ë²•ë ¹ë§Œ)
    if not force and target == "law":
        cached = find_cached_law(law_id=law_id)
        if cached:
            print(f"\nâœ… ìºì‹œëœ íŒŒì¼ ì‚¬ìš©: {cached}")
            tree = ET.parse(cached)
            root = tree.getroot()
            law_name = root.findtext('.//ë²•ë ¹ëª…_í•œê¸€', '') or root.findtext('.//ë²•ë ¹ëª…', '')
            promul_date = root.findtext('.//ê³µí¬ì¼ì', '')
            enforce_date = root.findtext('.//ì‹œí–‰ì¼ì', '')
            print(f"=== {law_name} ===")
            print(f"ê³µí¬ì¼: {promul_date} | ì‹œí–‰ì¼: {enforce_date}")
            print(f"(ê°•ì œ ë‹¤ìš´ë¡œë“œ: --force ì˜µì…˜ ì‚¬ìš©)")
            return root

    oc = load_config()

    # ìì¹˜ë²•ê·œëŠ” MST íŒŒë¼ë¯¸í„° ì‚¬ìš© (ë‹¤ë¥¸ íƒ€ì…ì€ ID)
    params = {
        'OC': oc,
        'target': target,
        'type': 'XML',
    }
    if target == 'ordin':
        params['MST'] = law_id
    else:
        params['ID'] = law_id

    root = api_request('lawService.do', params)

    # API ì˜¤ë¥˜ ì‘ë‹µ ê°ì§€ (ì¼ì¹˜í•˜ëŠ” ë°ì´í„° ì—†ìŒ)
    error_text = root.text.strip() if root.text else ''
    if 'ì¼ì¹˜í•˜ëŠ”' in error_text and 'ì—†ìŠµë‹ˆë‹¤' in error_text:
        target_name = TARGET_TYPE_NAMES.get(target, target)
        print(f"\nâŒ ì˜¤ë¥˜: ID '{law_id}'ì— í•´ë‹¹í•˜ëŠ” {target_name}ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", file=sys.stderr)
        print(f"   API ì‘ë‹µ: {error_text}", file=sys.stderr)
        sys.exit(1)

    # target íƒ€ì…ì— ë”°ë¼ ë‹¤ë¥¸ í•„ë“œ ì¶”ì¶œ ë° ì €ì¥
    if target == 'admrul':
        # í–‰ì •ê·œì¹™
        item_name = root.findtext('.//í–‰ì •ê·œì¹™ëª…', '') or root.findtext('.//í–‰ì •ê·œì¹™ëª…í•œê¸€', '')
        promul_date = root.findtext('.//ë°œë ¹ì¼ì', '')
        enforce_date = root.findtext('.//ì‹œí–‰ì¼ì', '')
        ministry = root.findtext('.//ì†Œê´€ë¶€ì²˜', '') or root.findtext('.//ì†Œê´€ë¶€ì²˜ëª…', '')
        admrul_type = root.findtext('.//í–‰ì •ê·œì¹™ì¢…ë¥˜', '')

        print(f"\n=== [{admrul_type}] {item_name} ===")
        print(f"ì†Œê´€: {ministry}")
        print(f"ë°œë ¹ì¼: {promul_date} | ì‹œí–‰ì¼: {enforce_date}")

        if save:
            safe_name = _sanitize_filename(item_name)
            filename = f"{safe_name}_{law_id}.xml"
            filepath = DATA_RAW_DIR / "admrul" / filename
            filepath.parent.mkdir(parents=True, exist_ok=True)
            tree = ET.ElementTree(root)
            tree.write(filepath, encoding='utf-8', xml_declaration=True)
            print(f"\nì €ì¥ë¨: {filepath}")

    elif target == 'ordin':
        # ìì¹˜ë²•ê·œ
        item_name = root.findtext('.//ìì¹˜ë²•ê·œëª…', '')
        promul_date = root.findtext('.//ê³µí¬ì¼ì', '')
        enforce_date = root.findtext('.//ì‹œí–‰ì¼ì', '')
        local_gov = root.findtext('.//ì§€ìì²´ê¸°ê´€ëª…', '')
        ordin_type = root.findtext('.//ìì¹˜ë²•ê·œì¢…ë¥˜', '')

        # ìì¹˜ë²•ê·œì¢…ë¥˜ ì½”ë“œë¥¼ í•œê¸€ë¡œ ë³€í™˜
        ordin_type_name = ORDIN_TYPE_MAP.get(ordin_type, ordin_type)

        print(f"\n=== [{ordin_type_name}] {item_name} ===")
        print(f"ì§€ìì²´: {local_gov}")
        print(f"ê³µí¬ì¼: {promul_date} | ì‹œí–‰ì¼: {enforce_date}")

        if save:
            safe_name = _sanitize_filename(item_name)
            filename = f"{safe_name}_{law_id}.xml"
            filepath = DATA_RAW_DIR / "ordin" / filename
            filepath.parent.mkdir(parents=True, exist_ok=True)
            tree = ET.ElementTree(root)
            tree.write(filepath, encoding='utf-8', xml_declaration=True)
            print(f"\nì €ì¥ë¨: {filepath}")

    elif target == 'expc':
        # ë²•ë ¹í•´ì„ë¡€
        item_name = root.findtext('.//ì•ˆê±´ëª…', '')
        case_number = root.findtext('.//ì•ˆê±´ë²ˆí˜¸', '')
        response_date = root.findtext('.//í•´ì„ì¼ì', '')
        request_org = root.findtext('.//ì§ˆì˜ê¸°ê´€ëª…', '')
        response_org = root.findtext('.//í•´ì„ê¸°ê´€ëª…', '')

        print(f"\n=== ë²•ë ¹í•´ì„ë¡€: {item_name} ===")
        print(f"ì•ˆê±´ë²ˆí˜¸: {case_number}")
        print(f"ì§ˆì˜: {request_org} â†’ í•´ì„: {response_org}")
        print(f"í•´ì„ì¼: {response_date}")

        # ì§ˆì˜ìš”ì§€/íšŒë‹µ ì¶œë ¥
        question = root.findtext('.//ì§ˆì˜ìš”ì§€', '')
        answer = root.findtext('.//íšŒë‹µ', '')
        if question:
            print(f"\nã€ì§ˆì˜ìš”ì§€ã€‘")
            print(question[:500] + "..." if len(question) > 500 else question)
        if answer:
            print(f"\nã€íšŒë‹µã€‘")
            print(answer[:500] + "..." if len(answer) > 500 else answer)

        if save:
            safe_name = _sanitize_filename(case_number)
            filename = f"{safe_name}_{law_id}.xml"
            filepath = DATA_RAW_DIR / "expc" / filename
            filepath.parent.mkdir(parents=True, exist_ok=True)
            tree = ET.ElementTree(root)
            tree.write(filepath, encoding='utf-8', xml_declaration=True)
            print(f"\nì €ì¥ë¨: {filepath}")

    elif target == 'detc':
        # í—Œì¬ê²°ì •ë¡€
        item_name = root.findtext('.//ì‚¬ê±´ëª…', '')
        case_number = root.findtext('.//ì‚¬ê±´ë²ˆí˜¸', '')
        decision_date = root.findtext('.//ì¢…êµ­ì¼ì', '')
        case_type = root.findtext('.//ì‚¬ê±´ì¢…ë¥˜ëª…', '')

        print(f"\n=== í—Œì¬ê²°ì •ë¡€: {item_name} ===")
        print(f"ì‚¬ê±´ë²ˆí˜¸: {case_number}")
        print(f"ì‚¬ê±´ì¢…ë¥˜: {case_type}")
        print(f"ì¢…êµ­ì¼: {decision_date}")

        # íŒì‹œì‚¬í•­/ê²°ì •ìš”ì§€ ì¶œë ¥
        points = root.findtext('.//íŒì‹œì‚¬í•­', '')
        summary = root.findtext('.//ê²°ì •ìš”ì§€', '')
        if points:
            print(f"\nã€íŒì‹œì‚¬í•­ã€‘")
            print(_clean_html_text(points, max_length=500))
        if summary:
            print(f"\nã€ê²°ì •ìš”ì§€ã€‘")
            print(_clean_html_text(summary, max_length=500))

        if save:
            safe_name = _sanitize_filename(case_number)
            filename = f"{safe_name}_{law_id}.xml"
            filepath = DATA_RAW_DIR / "detc" / filename
            filepath.parent.mkdir(parents=True, exist_ok=True)
            tree = ET.ElementTree(root)
            tree.write(filepath, encoding='utf-8', xml_declaration=True)
            print(f"\nì €ì¥ë¨: {filepath}")

    elif target == 'prec':
        # íŒë¡€ (fetch_case_by_idì™€ ë™ì¼í•œ ë¡œì§)
        item_name = root.findtext('.//ì‚¬ê±´ëª…', '')
        case_number = root.findtext('.//ì‚¬ê±´ë²ˆí˜¸', '')
        court_name = root.findtext('.//ë²•ì›ëª…', '')
        judge_date = root.findtext('.//ì„ ê³ ì¼ì', '')

        print(f"\n=== {item_name} ===")
        print(f"ì‚¬ê±´ë²ˆí˜¸: {case_number}")
        print(f"ë²•ì›: {court_name} | ì„ ê³ ì¼: {format_court_date(judge_date)}")

        # íŒì‹œì‚¬í•­/íŒê²°ìš”ì§€ ì¶œë ¥
        points = root.findtext('.//íŒì‹œì‚¬í•­', '')
        summary = root.findtext('.//íŒê²°ìš”ì§€', '')
        if points:
            print(f"\nã€íŒì‹œì‚¬í•­ã€‘")
            print(_clean_html_text(points, preserve_breaks=True, max_length=500))
        if summary:
            print(f"\nã€íŒê²°ìš”ì§€ã€‘")
            print(_clean_html_text(summary, preserve_breaks=True, max_length=500))

        if save:
            safe_name = _sanitize_filename(case_number)
            filename = f"{safe_name}_{law_id}.xml"
            filepath = DATA_RAW_DIR / "prec" / filename
            filepath.parent.mkdir(parents=True, exist_ok=True)
            tree = ET.ElementTree(root)
            tree.write(filepath, encoding='utf-8', xml_declaration=True)
            print(f"\nì €ì¥ë¨: {filepath}")

    else:
        # ë²•ë ¹ (ê¸°ë³¸)
        item_name = root.findtext('.//ë²•ë ¹ëª…_í•œê¸€', '') or root.findtext('.//ë²•ë ¹ëª…', '')
        promul_date = root.findtext('.//ê³µí¬ì¼ì', '')
        enforce_date = root.findtext('.//ì‹œí–‰ì¼ì', '')

        print(f"\n=== {item_name} ===")
        print(f"ê³µí¬ì¼: {promul_date} | ì‹œí–‰ì¼: {enforce_date}")

        if save:
            safe_name = _sanitize_filename(item_name)
            filename = f"{safe_name}_{law_id}.xml"
            filepath = DATA_RAW_DIR / filename
            DATA_RAW_DIR.mkdir(parents=True, exist_ok=True)
            tree = ET.ElementTree(root)
            tree.write(filepath, encoding='utf-8', xml_declaration=True)
            print(f"\nì €ì¥ë¨: {filepath}")

    return root


def fetch_law_by_name(name: str, with_decree: bool = False, force: bool = False):
    """ë²•ë ¹ëª…ìœ¼ë¡œ ê²€ìƒ‰ í›„ ì²« ë²ˆì§¸ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ"""
    # ìºì‹œ í™•ì¸
    if not force:
        cached = find_cached_law(law_name=name)
        if cached:
            print(f"\nâœ… ìºì‹œëœ íŒŒì¼ ì‚¬ìš©: {cached}")
            tree = ET.parse(cached)
            root = tree.getroot()
            law_name = root.findtext('.//ë²•ë ¹ëª…_í•œê¸€', '') or root.findtext('.//ë²•ë ¹ëª…', '')
            promul_date = root.findtext('.//ê³µí¬ì¼ì', '')
            enforce_date = root.findtext('.//ì‹œí–‰ì¼ì', '')
            print(f"=== {law_name} ===")
            print(f"ê³µí¬ì¼: {promul_date} | ì‹œí–‰ì¼: {enforce_date}")
            print(f"(ê°•ì œ ë‹¤ìš´ë¡œë“œ: --force ì˜µì…˜ ì‚¬ìš©)")
            return root

    # ì£¼ìš” ë²•ë ¹ì¸ ê²½ìš° ì„¤ì • íŒŒì¼ì—ì„œ ID ì§ì ‘ ì¡°íšŒ
    major_law_id = get_major_law_id(name)
    if major_law_id:
        print(f"ğŸ“Œ '{name}'ì€ ì£¼ìš” ë²•ë ¹ì…ë‹ˆë‹¤. (ID: {major_law_id})")
        return fetch_law_by_id(major_law_id, force=True)

    results = search_laws(name, display=5)

    if not results:
        print(f"Error: '{name}' ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.", file=sys.stderr)
        sys.exit(1)

    # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ë²•ë ¹ ì°¾ê¸°
    exact_match = None
    for r in results:
        if r['name'] == name or r['name'].replace(' ', '') == name.replace(' ', ''):
            exact_match = r
            break

    target = exact_match or results[0]
    law_id = target['id']
    print(f"\n'{target['name']}' ë‹¤ìš´ë¡œë“œ ì¤‘...")
    root = fetch_law_by_id(law_id, force=True)  # ì´ë¯¸ ìºì‹œ í™•ì¸í–ˆìœ¼ë¯€ë¡œ force=True

    # ì‹œí–‰ë ¹ë„ í•¨ê»˜ ë‹¤ìš´ë¡œë“œ
    if with_decree:
        decree_name = f"{name}ì‹œí–‰ë ¹"
        print(f"\n'{decree_name}' ê²€ìƒ‰ ì¤‘...")
        decree_results = search_laws(decree_name, display=3)

        if decree_results:
            for dr in decree_results:
                if 'ì‹œí–‰ë ¹' in dr['name']:
                    print(f"'{dr['name']}' ë‹¤ìš´ë¡œë“œ ì¤‘...")
                    fetch_law_by_id(dr['id'])
                    break

        # ì‹œí–‰ê·œì¹™ë„ ê²€ìƒ‰
        rule_name = f"{name}ì‹œí–‰ê·œì¹™"
        print(f"\n'{rule_name}' ê²€ìƒ‰ ì¤‘...")
        rule_results = search_laws(rule_name, display=3)

        if rule_results:
            for rr in rule_results:
                if 'ì‹œí–‰ê·œì¹™' in rr['name']:
                    print(f"'{rr['name']}' ë‹¤ìš´ë¡œë“œ ì¤‘...")
                    fetch_law_by_id(rr['id'])
                    break

    return root


def get_recent_laws(days: int = 30, from_date: str = None, to_date: str = None, target: str = "law", date_type: str = "ef", output_format: str = "text"):
    """
    ìµœê·¼ ê°œì • ë²•ë ¹ ì¡°íšŒ

    Args:
        days: ìµœê·¼ Nì¼
        from_date: ì‹œì‘ì¼ (YYYYMMDD)
        to_date: ì¢…ë£Œì¼ (YYYYMMDD)
        target: ê²€ìƒ‰ ëŒ€ìƒ
        date_type: ë‚ ì§œ ê¸°ì¤€ (ef: ì‹œí–‰ì¼, anc: ê³µí¬ì¼)
        output_format: ì¶œë ¥ í˜•ì‹ (text: í…ìŠ¤íŠ¸, json: JSON)
    """
    is_json = output_format == 'json'
    oc = load_config()

    # ë‚ ì§œ ë²”ìœ„ ê³„ì‚°
    if from_date and to_date:
        date_range = f"{from_date}~{to_date}"
    else:
        end = datetime.now()
        start = end - timedelta(days=days)
        from_date = start.strftime('%Y%m%d')
        to_date = end.strftime('%Y%m%d')
        date_range = f"{from_date}~{to_date}"

    params = {
        'OC': oc,
        'target': target,
        'type': 'XML',
        'display': 100,
        'sort': 'efdes',  # ì‹œí–‰ì¼ì ë‚´ë¦¼ì°¨ìˆœ
    }

    # ë‚ ì§œ ë²”ìœ„ íŒŒë¼ë¯¸í„° ì¶”ê°€ (efYd: ì‹œí–‰ì¼ì, ancYd: ê³µí¬ì¼ì)
    if date_type == "anc":
        params['ancYd'] = date_range
        params['sort'] = 'ddes'  # ê³µí¬ì¼ì ë‚´ë¦¼ì°¨ìˆœ
    else:
        params['efYd'] = date_range

    root = api_request('lawSearch.do', params)

    total = root.findtext('.//totalCnt', '0')
    date_type_name = "ê³µí¬ì¼" if date_type == "anc" else "ì‹œí–‰ì¼"
    if not is_json:
        print(f"\n=== ìµœê·¼ ë²•ë ¹ ëª©ë¡ ({date_type_name} ê¸°ì¤€: {date_range}) - ì´ {total}ê±´ ===\n")

    results = []
    for item in root.findall('.//law'):
        law_id = item.findtext('ë²•ë ¹ID', '')
        law_name = item.findtext('ë²•ë ¹ëª…í•œê¸€', '') or item.findtext('ë²•ë ¹ëª…', '')
        promul_date = item.findtext('ê³µí¬ì¼ì', '')
        enforce_date = item.findtext('ì‹œí–‰ì¼ì', '')
        ministry = item.findtext('ì†Œê´€ë¶€ì²˜ëª…', '')
        revision_type = item.findtext('ì œê°œì •êµ¬ë¶„ëª…', '')

        results.append({
            'id': law_id,
            'name': law_name,
            'promul_date': promul_date,
            'enforce_date': enforce_date,
            'ministry': ministry,
            'revision_type': revision_type,
        })

        if not is_json:
            revision_emoji = "ğŸ†•" if revision_type == "ì œì •" else "ğŸ“"
            print(f"{revision_emoji} [{revision_type}] {law_name}")
            print(f"   ê³µí¬ì¼: {promul_date} | ì‹œí–‰ì¼: {enforce_date}")
            print(f"   ì†Œê´€: {ministry}")
            print()

    if is_json:
        output = {
            'date_range': date_range,
            'date_type': date_type_name,
            'total': int(total),
            'results': results,
        }
        print(json.dumps(output, ensure_ascii=False, indent=2))
    else:
        print(f"í‘œì‹œ: {len(results)}ê±´ / ì „ì²´: {total}ê±´")

    return results


def search_exact_law(name: str, with_admrul: bool = False, output_format: str = "text"):
    """
    ì •í™•í•œ ë²•ë ¹ëª…ìœ¼ë¡œ ê²€ìƒ‰ (í´ë¼ì´ì–¸íŠ¸ì¸¡ í•„í„°ë§)

    Args:
        name: ì •í™•í•œ ë²•ë ¹ëª… (ì˜ˆ: "ìƒë²•", "ë¯¼ë²•")
        with_admrul: ê´€ë ¨ í–‰ì •ê·œì¹™ë„ í•¨ê»˜ ê²€ìƒ‰ ì—¬ë¶€
        output_format: ì¶œë ¥ í˜•ì‹ (text: í…ìŠ¤íŠ¸, json: JSON)

    Note:
        APIëŠ” ë¶€ë¶„ ì¼ì¹˜ ê²€ìƒ‰ë§Œ ì§€ì›í•˜ë¯€ë¡œ, ê²°ê³¼ì—ì„œ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ê²ƒë§Œ í•„í„°ë§
    """
    is_json = output_format == 'json'

    # ì£¼ìš” ë²•ë ¹ì¸ ê²½ìš° ì„¤ì • íŒŒì¼ì—ì„œ ID ì§ì ‘ í™œìš©
    major_law_id = get_major_law_id(name)
    if major_law_id and not is_json:
        print(f"\nğŸ’¡ '{name}'ì€ ì£¼ìš” ë²•ë ¹ì…ë‹ˆë‹¤. ì§ì ‘ ì¡°íšŒí•©ë‹ˆë‹¤...")
        print(f"   â†’ python scripts/fetch_law.py fetch --id {major_law_id}\n")

    oc = load_config()

    # ì¶©ë¶„í•œ ê²°ê³¼ë¥¼ ê°€ì ¸ì™€ì„œ í•„í„°ë§
    params = {
        'OC': oc,
        'target': 'law',
        'type': 'XML',
        'query': name,
        'display': 100,
    }

    root = api_request('lawSearch.do', params)

    if not is_json:
        print(f"\n=== ë²•ë ¹ ì •í™• ê²€ìƒ‰: '{name}' ===\n")

    results = []
    exact_matches = []
    related_matches = []

    for item in root.findall('.//law'):
        law_id = item.findtext('ë²•ë ¹ID', '')
        law_name = item.findtext('ë²•ë ¹ëª…í•œê¸€', '') or item.findtext('ë²•ë ¹ëª…', '')
        promul_date = item.findtext('ê³µí¬ì¼ì', '')
        enforce_date = item.findtext('ì‹œí–‰ì¼ì', '')
        ministry = item.findtext('ì†Œê´€ë¶€ì²˜ëª…', '')
        law_type = item.findtext('ë²•ë ¹êµ¬ë¶„ëª…', '')

        result = {
            'id': law_id,
            'name': law_name,
            'promul_date': promul_date,
            'enforce_date': enforce_date,
            'ministry': ministry,
            'type': law_type,
        }

        # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
        clean_name = name.replace(' ', '')
        clean_law_name = law_name.replace(' ', '')

        if clean_law_name == clean_name:
            exact_matches.append(result)
        elif clean_law_name.startswith(clean_name) and ('ì‹œí–‰ë ¹' in law_name or 'ì‹œí–‰ê·œì¹™' in law_name):
            related_matches.append(result)

    # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ë²•ë ¹ ì¶œë ¥
    if exact_matches:
        if not is_json:
            print("ğŸ“Œ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ë²•ë ¹:\n")
            for r in exact_matches:
                print(f"ğŸ“œ {r['name']}")
                print(f"   ID: {r['id']}")
                print(f"   êµ¬ë¶„: {r['type']} | ì†Œê´€: {r['ministry']}")
                print(f"   ê³µí¬ì¼: {r['promul_date']} | ì‹œí–‰ì¼: {r['enforce_date']}")
                print(f"   ë§í¬: https://www.law.go.kr/ë²•ë ¹/{urllib.parse.quote(r['name'])}")
                print()
        results.extend(exact_matches)
    elif not is_json:
        print(f"âš ï¸  '{name}'ê³¼ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ë²•ë ¹ì´ ì—†ìŠµë‹ˆë‹¤.\n")

    # ê´€ë ¨ ë²•ë ¹ (ì‹œí–‰ë ¹, ì‹œí–‰ê·œì¹™) ì¶œë ¥
    if related_matches:
        if not is_json:
            print("ğŸ“ ê´€ë ¨ ë²•ë ¹ (ì‹œí–‰ë ¹/ì‹œí–‰ê·œì¹™):\n")
            for r in related_matches:
                print(f"ğŸ“œ {r['name']}")
                print(f"   ID: {r['id']}")
                print(f"   êµ¬ë¶„: {r['type']} | ì†Œê´€: {r['ministry']}")
                print(f"   ê³µí¬ì¼: {r['promul_date']} | ì‹œí–‰ì¼: {r['enforce_date']}")
                print()
        results.extend(related_matches)

    if not results and not is_json:
        print(f"ğŸ’¡ íŒíŠ¸: '{name}'ì„ í¬í•¨í•˜ëŠ” ë²•ë ¹ì„ ê²€ìƒ‰í•˜ë ¤ë©´:")
        print(f"   python scripts/fetch_law.py search \"{name}\"")

    # ê´€ë ¨ í–‰ì •ê·œì¹™ ê²€ìƒ‰
    admin_rules = []
    if with_admrul:
        if not is_json:
            print(f"\n{'='*60}")
            print(f"ğŸ“‹ ê´€ë ¨ í–‰ì •ê·œì¹™ (ê³ ì‹œ/í›ˆë ¹/ì˜ˆê·œ) ê²€ìƒ‰ ì¤‘...")
            print(f"{'='*60}")
        admin_rules = search_related_admin_rules(name, output_format=output_format)

    # JSON ì¶œë ¥
    if is_json:
        output = {
            'query': name,
            'exact_matches': exact_matches,
            'related_laws': related_matches,
            'admin_rules': admin_rules if with_admrul else [],
        }
        print(json.dumps(output, ensure_ascii=False, indent=2))

    return results


def search_related_admin_rules(law_name: str, display: int = 10, output_format: str = "text"):
    """
    ë²•ë ¹ëª…ê³¼ ê´€ë ¨ëœ í–‰ì •ê·œì¹™ ê²€ìƒ‰

    Args:
        law_name: ë²•ë ¹ëª… (ì˜ˆ: "ê°œì¸ì •ë³´ë³´í˜¸ë²•", "ê·¼ë¡œê¸°ì¤€ë²•")
        display: í‘œì‹œí•  ê²°ê³¼ ìˆ˜
        output_format: ì¶œë ¥ í˜•ì‹ (text: í…ìŠ¤íŠ¸, json: JSON)
    """
    is_json = output_format == 'json'
    oc = load_config()

    # ë‹¤ì–‘í•œ ê²€ìƒ‰ íŒ¨í„´ ì‹œë„
    search_terms = [
        law_name,  # ë²•ë ¹ëª… ê·¸ëŒ€ë¡œ
        f"{law_name} ì‹œí–‰",  # ì‹œí–‰ ê´€ë ¨
        f"{law_name} ê¸°ì¤€",  # ê¸°ì¤€ ê´€ë ¨
    ]

    all_results = []
    seen_ids = set()

    for term in search_terms:
        params = {
            'OC': oc,
            'target': 'admrul',
            'type': 'XML',
            'query': term,
            'display': display,
        }

        try:
            root = api_request('lawSearch.do', params)

            for item in root.findall('.//admrul'):
                admrul_id = item.findtext('í–‰ì •ê·œì¹™ì¼ë ¨ë²ˆí˜¸', '')
                if admrul_id in seen_ids:
                    continue
                seen_ids.add(admrul_id)

                admrul_name = item.findtext('í–‰ì •ê·œì¹™ëª…', '')
                admrul_type = item.findtext('í–‰ì •ê·œì¹™ì¢…ë¥˜', '')
                promul_date = item.findtext('ë°œë ¹ì¼ì', '')
                enforce_date = item.findtext('ì‹œí–‰ì¼ì', '')
                ministry = item.findtext('ì†Œê´€ë¶€ì²˜ëª…', '')

                all_results.append({
                    'id': admrul_id,
                    'name': admrul_name,
                    'type': admrul_type,
                    'promul_date': promul_date,
                    'enforce_date': enforce_date,
                    'ministry': ministry,
                })
        except (urllib.error.HTTPError, urllib.error.URLError, ET.ParseError):
            # API ì˜¤ë¥˜ ì‹œ ë‹¤ìŒ ê²€ìƒ‰ì–´ë¡œ ê³„ì†
            continue

    if not is_json:
        if all_results:
            print(f"\n=== '{law_name}' ê´€ë ¨ í–‰ì •ê·œì¹™ (ì´ {len(all_results)}ê±´) ===\n")
            print("âš ï¸  ì‹¤ë¬´ íŒ: ë²•ë¥ ì€ í° í‹€ë§Œ ì •í•©ë‹ˆë‹¤. êµ¬ì²´ì ì¸ ê¸°ì¤€/ì ˆì°¨/ì„œì‹ì€")
            print("   ì•„ë˜ í–‰ì •ê·œì¹™(ê³ ì‹œ/í›ˆë ¹/ì˜ˆê·œ)ì—ì„œ í™•ì¸í•˜ì„¸ìš”!\n")

            for r in all_results[:display]:
                print(f"ğŸ“‹ [{r['type']}] {r['name']}")
                print(f"   ID: {r['id']}")
                print(f"   ì†Œê´€: {r['ministry']}")
                print(f"   ë°œë ¹ì¼: {r['promul_date']} | ì‹œí–‰ì¼: {r['enforce_date']}")
                print(f"   ë§í¬: https://www.law.go.kr/í–‰ì •ê·œì¹™/{urllib.parse.quote(r['name'])}")
                print()
        else:
            print(f"\n'{law_name}' ê´€ë ¨ í–‰ì •ê·œì¹™ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            print(f"ğŸ’¡ ì§ì ‘ ê²€ìƒ‰: python scripts/fetch_law.py search \"{law_name}\" --type admrul")

    return all_results


def fetch_case_by_id(case_id: str, save: bool = True):
    """
    íŒë¡€ IDë¡œ ë³¸ë¬¸ ì¡°íšŒ

    Args:
        case_id: íŒë¡€ì¼ë ¨ë²ˆí˜¸
        save: íŒŒì¼ë¡œ ì €ì¥ ì—¬ë¶€
    """
    oc = load_config()

    params = {
        'OC': oc,
        'target': 'prec',
        'type': 'XML',
        'ID': case_id,
    }

    root = api_request('lawService.do', params)

    # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
    case_name = root.findtext('.//ì‚¬ê±´ëª…', '')
    case_number = root.findtext('.//ì‚¬ê±´ë²ˆí˜¸', '')
    court_name = root.findtext('.//ë²•ì›ëª…', '')
    judge_date = root.findtext('.//ì„ ê³ ì¼ì', '')

    print(f"\n=== {case_name} ===")
    print(f"ì‚¬ê±´ë²ˆí˜¸: {case_number}")
    print(f"ë²•ì›: {court_name} | ì„ ê³ ì¼: {format_court_date(judge_date)}")

    # íŒì‹œì‚¬í•­
    points = root.findtext('.//íŒì‹œì‚¬í•­', '')
    if points:
        print(f"\nã€íŒì‹œì‚¬í•­ã€‘")
        print(_clean_html_text(points, preserve_breaks=True))

    # íŒê²°ìš”ì§€
    summary = root.findtext('.//íŒê²°ìš”ì§€', '')
    if summary:
        print(f"\nã€íŒê²°ìš”ì§€ã€‘")
        print(_clean_html_text(summary, preserve_breaks=True))

    if save:
        safe_name = _sanitize_filename(case_number)
        filename = f"{safe_name}_{case_id}.xml"
        filepath = DATA_RAW_DIR / "prec" / filename

        # XML ì €ì¥
        filepath.parent.mkdir(parents=True, exist_ok=True)
        tree = ET.ElementTree(root)
        tree.write(filepath, encoding='utf-8', xml_declaration=True)
        print(f"\nì €ì¥ë¨: {filepath}")

    return root


def fetch_case_by_number(case_number: str):
    """ì‚¬ê±´ë²ˆí˜¸ë¡œ ê²€ìƒ‰ í›„ ì²« ë²ˆì§¸ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ"""
    results = search_cases(case_number, display=5)

    if not results:
        print(f"Error: '{case_number}' ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.", file=sys.stderr)
        sys.exit(1)

    # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” íŒë¡€ ì°¾ê¸°
    exact_match = None
    clean_number = case_number.replace(' ', '')
    for r in results:
        if r['case_number'].replace(' ', '') == clean_number:
            exact_match = r
            break

    target = exact_match or results[0]
    case_id = target['id']
    print(f"\n'{target['case_number']}' ë‹¤ìš´ë¡œë“œ ì¤‘...")
    return fetch_case_by_id(case_id)


# ============================================================
# ì²´í¬ë¦¬ìŠ¤íŠ¸ ê¸°ëŠ¥
# ============================================================

def _generate_law_link(law_name: str, articles: list = None) -> str:
    """ë²•ë ¹ ë§í¬ ìƒì„± (gen_link.py ë¡œì§ ì¬ì‚¬ìš©)"""
    encoded_name = urllib.parse.quote(law_name)
    base_url = f"https://www.law.go.kr/ë²•ë ¹/{encoded_name}"

    if articles:
        # ì²« ë²ˆì§¸ ì¡°í•­ìœ¼ë¡œ ì•µì»¤ ë§í¬ ìƒì„±
        return base_url
    return base_url


def list_checklists():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì²´í¬ë¦¬ìŠ¤íŠ¸/ì¡°ì‚¬ê°€ì´ë“œ ëª©ë¡ ì¶œë ¥"""
    if not CHECKLISTS_DIR.exists():
        print("ì²´í¬ë¦¬ìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.", file=sys.stderr)
        return []

    checklists = []
    guides = []
    for filepath in sorted(CHECKLISTS_DIR.glob("*.yaml")):
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f)
                if data:
                    item = {
                        'name': filepath.stem,
                        'title': data.get('name', filepath.stem),
                        'description': data.get('description', ''),
                        'category': data.get('category', ''),
                        'item_count': len(data.get('items', [])),
                        'type': data.get('type', 'checklist'),
                    }
                    if item['type'] == 'research_guide':
                        guides.append(item)
                    else:
                        checklists.append(item)
        except (yaml.YAMLError, OSError) as e:
            print(f"Warning: {filepath.name} ë¡œë“œ ì‹¤íŒ¨ - {e}", file=sys.stderr)
            continue

    # ì²´í¬ë¦¬ìŠ¤íŠ¸ ì¶œë ¥
    if checklists:
        print("\n=== ì²´í¬ë¦¬ìŠ¤íŠ¸ (ì ˆì°¨ì  ì ê²€) ===\n")
        for cl in checklists:
            print(f"ğŸ“‹ {cl['name']}")
            print(f"   ì œëª©: {cl['title']}")
            print(f"   ì„¤ëª…: {cl['description']}")
            print(f"   ë¶„ë¥˜: {cl['category']} | í•­ëª© ìˆ˜: {cl['item_count']}ê°œ")
            print()

    # ì¡°ì‚¬ ê°€ì´ë“œ ì¶œë ¥
    if guides:
        print("=== ì¡°ì‚¬ ê°€ì´ë“œ (íƒìƒ‰ì  ì§ˆë¬¸) ===\n")
        print("âš ï¸  ì¡°ì‚¬ ê°€ì´ë“œëŠ” 'ì²´í¬ë¦¬ìŠ¤íŠ¸'ê°€ ì•„ë‹™ë‹ˆë‹¤!")
        print("   ë§¥ë½ì— ë”°ë¼ íŒë‹¨ì´ ë‹¬ë¼ì§€ë¯€ë¡œ, ì§ˆë¬¸ì„ ì‹œì‘ì ìœ¼ë¡œ ì‹¬ì¸µ ì¡°ì‚¬í•˜ì„¸ìš”.\n")
        for g in guides:
            print(f"ğŸ” {g['name']}")
            print(f"   ì œëª©: {g['title']}")
            print(f"   ì„¤ëª…: {g['description']}")
            print(f"   ë¶„ë¥˜: {g['category']} | ì§ˆë¬¸ ìˆ˜: {g['item_count']}ê°œ")
            print()

    print("ì‚¬ìš©ë²•: python scripts/fetch_law.py checklist show <name>")
    print("ì˜ˆì‹œ: python scripts/fetch_law.py checklist show startup")
    return checklists + guides


def show_checklist(name: str, output_file: str = None, output_format: str = "markdown"):
    """ì²´í¬ë¦¬ìŠ¤íŠ¸/ì¡°ì‚¬ê°€ì´ë“œ ì¶œë ¥ (ë²•ë ¹ ë§í¬ ìë™ ìƒì„±)

    Args:
        name: ì²´í¬ë¦¬ìŠ¤íŠ¸ ì´ë¦„ (í™•ì¥ì ì—†ì´)
        output_file: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (ì—†ìœ¼ë©´ stdout)
        output_format: ì¶œë ¥ í˜•ì‹ (markdown, json)
    """
    filepath = CHECKLISTS_DIR / f"{name}.yaml"

    if not filepath.exists():
        print(f"Error: '{name}' ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", file=sys.stderr)
        print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì²´í¬ë¦¬ìŠ¤íŠ¸: python scripts/fetch_law.py checklist list", file=sys.stderr)
        sys.exit(1)

    with open(filepath, 'r', encoding='utf-8') as f:
        data = yaml.safe_load(f)

    # ë¹ˆ YAML íŒŒì¼ ì²´í¬
    if not data:
        print(f"Error: '{name}' ì²´í¬ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.", file=sys.stderr)
        sys.exit(1)

    if output_format == 'json':
        # JSON ì¶œë ¥
        output = json.dumps(data, ensure_ascii=False, indent=2)
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(output)
            print(f"ì €ì¥ë¨: {output_file}")
        else:
            print(output)
        return data

    # íƒ€ì… í™•ì¸ (research_guide vs checklist)
    doc_type = data.get('type', 'checklist')
    is_research_guide = doc_type == 'research_guide'

    # Markdown ì¶œë ¥ ìƒì„±
    lines = []
    lines.append(f"# {data.get('name', name)}")
    lines.append("")
    lines.append(f"> {data.get('description', '')}")
    lines.append("")

    # ê²½ê³  ë¬¸êµ¬ (research_guideì¸ ê²½ìš°)
    warnings = data.get('warnings', [])
    if warnings:
        lines.append("### âš ï¸ ì¤‘ìš”")
        for w in warnings:
            lines.append(f"- {w}")
        lines.append("")

    lines.append(f"**ë¶„ë¥˜**: {data.get('category', '')} | **ìµœì¢… ì—…ë°ì´íŠ¸**: {data.get('last_updated', '')}")
    lines.append("")

    # ì´ˆê¸° ë¶„ê¸° ì§ˆë¬¸ (Quick Triage)
    triage = data.get('triage_questions', [])
    if triage:
        lines.append("## ğŸ”€ ì´ˆê¸° ë¶„ê¸° ì§ˆë¬¸")
        lines.append("")
        for t in triage:
            q = t.get('question', '')
            lines.append(f"**{q}**")
            if 'if_yes' in t:
                lines.append(f"  - Yes â†’ {t['if_yes']}")
            if 'branches' in t:
                for b in t['branches']:
                    lines.append(f"  - {b}")
            if 'thresholds' in t:
                for th in t['thresholds']:
                    lines.append(f"  - {th}")
            if 'examples' in t:
                for ex in t['examples']:
                    lines.append(f"    - {ex}")
            lines.append("")
        lines.append("---")
        lines.append("")

    # ì—°ê´€ ì²´í¬ë¦¬ìŠ¤íŠ¸
    related = data.get('related_checklists', [])
    if related:
        lines.append("## ğŸ“ ì—°ê´€ ì²´í¬ë¦¬ìŠ¤íŠ¸")
        lines.append("")
        for r in related:
            lines.append(f"- **{r.get('name', '')}**: {r.get('when', '')}")
        lines.append("")
        lines.append("---")
        lines.append("")

    for i, item in enumerate(data.get('items', []), 1):
        if is_research_guide:
            # ì¡°ì‚¬ ê°€ì´ë“œ í˜•ì‹
            question = item.get('question', '')
            lines.append(f"## {i}. {question}")
            lines.append("")

            # ì™œ ì¤‘ìš”í•œì§€
            why = item.get('why_it_matters', '')
            if why:
                lines.append("**ì™œ ì¤‘ìš”í•œê°€:**")
                for line in why.strip().split('\n'):
                    lines.append(f"> {line.strip()}")
                lines.append("")

            # ì¡°ì‚¬ ì•¡ì…˜
            research_actions = item.get('research_actions', [])
            if research_actions:
                lines.append("**ì¡°ì‚¬ ë°©ë²•:**")
                for action in research_actions:
                    lines.append(f"```")
                    lines.append(action)
                    lines.append(f"```")
                lines.append("")

            # í•µì‹¬ ì§ˆë¬¸
            key_questions = item.get('key_questions', [])
            if key_questions:
                lines.append("**ê²€í† í•  ì§ˆë¬¸:**")
                for q in key_questions:
                    lines.append(f"- â“ {q}")
                lines.append("")

            # ìœ„í—˜ ìš”ì†Œ
            risk_factors = item.get('risk_factors', [])
            if risk_factors:
                lines.append("**ìœ„í—˜ ì‹ í˜¸:**")
                for rf in risk_factors:
                    lines.append(f"- ğŸš¨ {rf}")
                lines.append("")

            # ì°¸ê³  ì‚¬í•­
            note = item.get('note', '')
            if note:
                lines.append(f"**ğŸ“Œ ì°¸ê³ **: {note}")
                lines.append("")

        else:
            # ê¸°ì¡´ ì²´í¬ë¦¬ìŠ¤íŠ¸ í˜•ì‹
            task = item.get('task', '')
            risk_level = item.get('risk_level', 'medium')
            risk_emoji = {'high': 'ğŸ”´', 'medium': 'ğŸŸ¡', 'low': 'ğŸŸ¢'}.get(risk_level, 'âšª')

            lines.append(f"## {i}. {task} {risk_emoji}")
            lines.append("")

            # ì¡°ê±´ í‘œì‹œ
            condition = item.get('condition')
            if condition:
                lines.append(f"**ì¡°ê±´**: {condition}")
                lines.append("")

            # ê¸°í•œ í‘œì‹œ
            deadline = item.get('deadline')
            if deadline:
                lines.append(f"**âš ï¸ ê¸°í•œ**: {deadline}")
                lines.append("")

            # ì ê²€ ì‚¬í•­
            check_points = item.get('check_points', [])
            if check_points:
                lines.append("**ì ê²€ ì‚¬í•­**:")
                for cp in check_points:
                    lines.append(f"- [ ] {cp}")
                lines.append("")

            # ì°¸ê³  ì‚¬í•­
            notes = item.get('notes', '')
            if notes:
                lines.append("**ì°¸ê³ **:")
                for note_line in notes.strip().split('\n'):
                    lines.append(f"> {note_line.strip()}")
                lines.append("")

        # ê³µí†µ: ê´€ë ¨ ë²•ë ¹ (ë§í¬ í¬í•¨)
        laws = item.get('laws', item.get('related_laws', []))
        if laws:
            lines.append("**ê´€ë ¨ ë²•ë ¹**:")
            for law in laws:
                if not isinstance(law, dict):
                    continue
                law_name = law.get('name', '')
                if not law_name:
                    continue
                articles = law.get('articles', [])
                link = _generate_law_link(law_name)

                if articles:
                    articles_str = ", ".join(str(a) for a in articles if a)
                    lines.append(f"- [{law_name}]({link}): {articles_str}")
                else:
                    lines.append(f"- [{law_name}]({link})")
            lines.append("")

        # ê³µí†µ: ê´€ë ¨ í–‰ì •ê·œì¹™
        admin_rules = item.get('admin_rules', [])
        if admin_rules:
            lines.append("**ê´€ë ¨ í–‰ì •ê·œì¹™ (ê³ ì‹œ/í›ˆë ¹)**:")
            for rule in admin_rules:
                if not isinstance(rule, str):
                    continue
                rule_link = f"https://www.law.go.kr/í–‰ì •ê·œì¹™/{urllib.parse.quote(rule)}"
                lines.append(f"- [{rule}]({rule_link})")
            lines.append("")

        lines.append("---")
        lines.append("")

    # ì¡°ì‚¬ ì›Œí¬í”Œë¡œìš° (research_guideì¸ ê²½ìš°)
    workflow = data.get('research_workflow', {})
    if workflow:
        lines.append("## ì¡°ì‚¬ ì›Œí¬í”Œë¡œìš°")
        lines.append("")
        for step_key in sorted(workflow.keys()):
            step = workflow[step_key]
            lines.append(f"**{step.get('name', step_key)}**: {step.get('action', '')}")
        lines.append("")
        lines.append("---")
        lines.append("")

    # ì´ ê°€ì´ë“œì—ì„œ ë‹¤ë£¨ì§€ ì•ŠëŠ” ì£¼ìš” ì´ìŠˆ (research_guide)
    not_covered = data.get('not_covered', [])
    if not_covered and isinstance(not_covered, list):
        lines.append("## âš ï¸ ì´ ê°€ì´ë“œì—ì„œ ë‹¤ë£¨ì§€ ì•ŠëŠ” ì´ìŠˆ")
        lines.append("")
        for nc in not_covered:
            if isinstance(nc, dict):
                area = nc.get('area', '')
                lines.append(f"**{area}** ({nc.get('when_relevant', '')})")
                for issue in nc.get('issues', []):
                    lines.append(f"  - {issue}")
            elif isinstance(nc, str):
                lines.append(f"- {nc}")
            lines.append("")
        lines.append("---")
        lines.append("")

    # ë†“ì¹˜ê¸° ì‰¬ìš´ í•­ëª© (Common Oversights)
    oversights = data.get('common_oversights', [])
    if oversights:
        lines.append("## ğŸ’¡ ë†“ì¹˜ê¸° ì‰¬ìš´ í•­ëª©")
        lines.append("")
        for o in oversights:
            item_name = o.get('item', '')
            issue = o.get('issue', '')
            action = o.get('action', o.get('tip', ''))
            lines.append(f"**{item_name}**")
            lines.append(f"  - ë¬¸ì œ: {issue}")
            lines.append(f"  - ì¡°ì¹˜: {action}")
            lines.append("")
        lines.append("---")
        lines.append("")

    # ì„±ì¥ ë‹¨ê³„ë³„ ê²€í†  (startup)
    growth = data.get('growth_stage_considerations', {})
    if growth:
        lines.append("## ğŸ“ˆ ì„±ì¥ ë‹¨ê³„ë³„ ì¶”ê°€ ê²€í† ")
        lines.append("")
        for stage, items in growth.items():
            stage_name = {'seed_stage': 'ğŸŒ± Seed', 'series_a_plus': 'ğŸš€ Series A+', 'scaling': 'ğŸ“Š Scaling'}.get(stage, stage)
            lines.append(f"**{stage_name}**")
            for item in items:
                lines.append(f"  - {item}")
            lines.append("")
        lines.append("---")
        lines.append("")

    # ì£¼ê¸°ì  ì ê²€ (privacy)
    periodic = data.get('periodic_review', {})
    if periodic:
        lines.append("## ğŸ”„ ì£¼ê¸°ì  ì ê²€ ì‚¬í•­")
        lines.append("")
        if 'annually' in periodic:
            lines.append("**ì—°ê°„**")
            for item in periodic['annually']:
                lines.append(f"  - {item}")
            lines.append("")
        if 'on_change' in periodic:
            lines.append("**ë³€ê²½ ì‹œ**")
            for item in periodic['on_change']:
                lines.append(f"  - {item}")
            lines.append("")
        lines.append("---")
        lines.append("")

    # ì—…ì¢…ë³„ ì¶”ê°€ ê²€í†  (privacy)
    sector_notes = data.get('sector_specific_notes', [])
    if sector_notes:
        lines.append("## ğŸ¢ ì—…ì¢…ë³„ ì¶”ê°€ ê²€í† ")
        lines.append("")
        for sn in sector_notes:
            lines.append(f"**{sn.get('sector', '')}**: {sn.get('additional', '')}")
        lines.append("")
        lines.append("---")
        lines.append("")

    # ì—°ê´€ ë²•ë ¹ ë§µ (fair_trade)
    laws_map = data.get('related_laws_map', [])
    if laws_map:
        lines.append("## ğŸ“š ìƒí™©ë³„ ì—°ê´€ ë²•ë ¹")
        lines.append("")
        for lm in laws_map:
            lines.append(f"**{lm.get('context', '')}**")
            for law in lm.get('laws', []):
                lines.append(f"  - {law}")
            if lm.get('note'):
                lines.append(f"  - ğŸ’¡ {lm['note']}")
            lines.append("")
        lines.append("---")
        lines.append("")

    # ì œì¬ ë™í–¥ í™•ì¸ íŒ (fair_trade)
    enforcement_tips = data.get('enforcement_check_tips', [])
    if enforcement_tips:
        lines.append("## ğŸ” ì œì¬ ë™í–¥ í™•ì¸ íŒ")
        lines.append("")
        for tip in enforcement_tips:
            lines.append(f"- {tip}")
        lines.append("")
        lines.append("---")
        lines.append("")

    # ì ìš© ëŒ€ìƒ (scope) - ì¤‘ëŒ€ì¬í•´ì²˜ë²Œë²• ë“±
    scope_items = data.get('scope', [])
    if scope_items:
        lines.append("## ğŸ“‹ ì ìš© ëŒ€ìƒ íŒë‹¨")
        lines.append("")
        for item in scope_items:
            if not isinstance(item, dict):
                continue
            task = item.get('task', '')
            if not task:
                continue
            lines.append(f"### {task}")
            for cp in item.get('check_points', []):
                if isinstance(cp, str):
                    lines.append(f"- [ ] {cp}")
            notes = item.get('notes', '')
            if notes:
                for note_line in str(notes).strip().split('\n'):
                    lines.append(f"> {note_line.strip()}")
            lines.append("")
        lines.append("---")
        lines.append("")

    # ì²˜ë²Œ ê·œì • (penalties) - ì¤‘ëŒ€ì¬í•´ì²˜ë²Œë²• ë“±
    penalties = data.get('penalties', {})
    if penalties:
        lines.append(f"## âš–ï¸ {penalties.get('title', 'ì²˜ë²Œ ê·œì •')}")
        lines.append("")
        individual = penalties.get('individual', {})
        if individual:
            lines.append("**ê°œì¸ (ê²½ì˜ì±…ì„ì ë“±)**")
            for key, val in individual.items():
                if isinstance(val, dict):
                    lines.append(f"- {val.get('description', key)}: {val.get('punishment', '')}")
            lines.append("")
        corporation = penalties.get('corporation', {})
        if corporation:
            lines.append("**ë²•ì¸**")
            for key, val in corporation.items():
                if isinstance(val, dict):
                    lines.append(f"- {val.get('description', key)}: {val.get('punishment', '')}")
            lines.append("")
        civil = penalties.get('civil', {})
        if civil:
            lines.append(f"**ë¯¼ì‚¬**: {civil.get('description', '')} - {civil.get('punishment', '')}")
            lines.append("")
        lines.append("---")
        lines.append("")

    # ê³„ì•½ ìœ í˜•ë³„ ê²€í†  (contract_types) - ê³„ì•½ì„œ ê²€í†  ê°€ì´ë“œ
    contract_types = data.get('contract_types', [])
    if contract_types:
        lines.append("## ğŸ“ ê³„ì•½ ìœ í˜•ë³„ ê²€í†  í¬ì¸íŠ¸")
        lines.append("")
        for ct in contract_types:
            if not isinstance(ct, dict):
                continue
            type_name = ct.get('type_name', '')
            if not type_name:
                continue
            lines.append(f"### {type_name}")
            lines.append("")
            for issue in ct.get('key_issues', []):
                if not isinstance(issue, dict):
                    continue
                issue_name = issue.get('issue', '')
                if issue_name:
                    lines.append(f"**{issue_name}**")
                for cp in issue.get('check_points', []):
                    if isinstance(cp, str):
                        lines.append(f"- [ ] {cp}")
                why = issue.get('why_it_matters', '')
                if why:
                    for line in str(why).strip().split('\n'):
                        lines.append(f"> {line.strip()}")
                lines.append("")
            lines.append("---")
            lines.append("")

    # ê³µí†µ ìœ„í—˜ ì¡°í•­ (common_risk_clauses) - ê³„ì•½ì„œ ê²€í†  ê°€ì´ë“œ
    risk_clauses = data.get('common_risk_clauses', [])
    if risk_clauses:
        lines.append("## âš ï¸ ê³µí†µ ìœ„í—˜ ì¡°í•­")
        lines.append("")
        for rc in risk_clauses:
            if not isinstance(rc, dict):
                continue
            risk_emoji = {'high': 'ğŸ”´', 'medium': 'ğŸŸ¡', 'low': 'ğŸŸ¢'}.get(rc.get('risk_level', 'medium'), 'âšª')
            clause_name = rc.get('clause', '')
            if not clause_name:
                continue
            lines.append(f"### {clause_name} {risk_emoji}")
            for cp in rc.get('check_points', []):
                if isinstance(cp, str):
                    lines.append(f"- [ ] {cp}")
            laws = rc.get('laws', [])
            if laws:
                lines.append("**ê´€ë ¨ ë²•ë ¹**:")
                for law in laws:
                    if not isinstance(law, dict):
                        continue
                    law_name = law.get('name', '')
                    if not law_name:
                        continue
                    articles = law.get('articles', [])
                    link = _generate_law_link(law_name)
                    if articles:
                        articles_str = ", ".join(str(a) for a in articles if a)
                        lines.append(f"- [{law_name}]({link}): {articles_str}")
                    else:
                        lines.append(f"- [{law_name}]({link})")
            lines.append("")
        lines.append("---")
        lines.append("")

    # ì‹¤ì‚¬ ì˜ì—­ (due_diligence_areas) - íˆ¬ì ì‹¤ì‚¬ ê°€ì´ë“œ
    dd_areas = data.get('due_diligence_areas', [])
    if dd_areas:
        lines.append("## ğŸ” ë²•ë¥ ì‹¤ì‚¬ ì˜ì—­")
        lines.append("")
        for area in dd_areas:
            if not isinstance(area, dict):
                continue
            area_name = area.get('area_name', '')
            if not area_name:
                continue
            lines.append(f"### {area_name}")
            lines.append("")
            for item in area.get('items', []):
                if not isinstance(item, dict):
                    continue
                item_name = item.get('item', '')
                if item_name:
                    lines.append(f"**{item_name}**")
                for cp in item.get('check_points', []):
                    if isinstance(cp, str):
                        lines.append(f"- [ ] {cp}")
                docs = item.get('documents', [])
                if docs:
                    doc_list = [str(d) for d in docs if d]
                    if doc_list:
                        lines.append("*í•„ìš” ì„œë¥˜*: " + ", ".join(doc_list))
                why = item.get('why_it_matters', '')
                if why:
                    for line in str(why).strip().split('\n'):
                        lines.append(f"> {line.strip()}")
                lines.append("")
            lines.append("---")
            lines.append("")

    # íˆ¬ìê³„ì•½ ì£¼ìš” ì¡°í•­ (investment_contract_terms)
    inv_terms = data.get('investment_contract_terms', {})
    if inv_terms and isinstance(inv_terms, dict):
        lines.append(f"## ğŸ’° {inv_terms.get('title', 'íˆ¬ìê³„ì•½ ì£¼ìš” ì¡°í•­')}")
        lines.append("")
        note = inv_terms.get('note', '')
        if note:
            for line in str(note).strip().split('\n'):
                lines.append(f"> {line.strip()}")
            lines.append("")
        for term in inv_terms.get('terms', []):
            if not isinstance(term, dict):
                continue
            term_name = term.get('term', '')
            if term_name:
                lines.append(f"**{term_name}**")
            for cp in term.get('check_points', []):
                if isinstance(cp, str):
                    lines.append(f"- [ ] {cp}")
            why = term.get('why_it_matters', '')
            if why:
                for line in str(why).strip().split('\n'):
                    lines.append(f"> {line.strip()}")
            lines.append("")
        lines.append("---")
        lines.append("")

    # ê·œëª¨ë³„ ì ìš© (scale_based_requirements) - ë…¸ë™ë²•
    scale_req = data.get('scale_based_requirements', {})
    if scale_req and isinstance(scale_req, dict):
        lines.append("## ğŸ“Š ê·œëª¨ë³„ ì ìš© ì •ë¦¬")
        lines.append("")
        for key, val in scale_req.items():
            if isinstance(val, dict):
                lines.append(f"**{val.get('name', key)}**")
                excluded = val.get('excluded', [])
                if excluded:
                    lines.append("*ì ìš© ì œì™¸*:")
                    for item in excluded:
                        if isinstance(item, str):
                            lines.append(f"  - âŒ {item}")
                applied = val.get('applied', [])
                if applied:
                    lines.append("*ì ìš©*:")
                    for item in applied:
                        if isinstance(item, str):
                            lines.append(f"  - âœ… {item}")
                additional = val.get('additional', [])
                if additional:
                    lines.append("*ì¶”ê°€ ì˜ë¬´*:")
                    for item in additional:
                        if isinstance(item, str):
                            lines.append(f"  - â• {item}")
                lines.append("")
        lines.append("---")
        lines.append("")

    # ì•½ê´€ê·œì œë²• ì°¸ê³  (unfair_terms_reference)
    unfair_ref = data.get('unfair_terms_reference', {})
    if unfair_ref and isinstance(unfair_ref, dict):
        lines.append(f"## ğŸ“– {unfair_ref.get('title', 'ì•½ê´€ê·œì œë²• ì°¸ê³ ')}")
        lines.append("")
        for law in unfair_ref.get('laws', []):
            if not isinstance(law, dict):
                continue
            law_name = law.get('name', '')
            if not law_name:
                continue
            link = _generate_law_link(law_name)
            lines.append(f"**[{law_name}]({link})**")
            for art in law.get('articles', []):
                if isinstance(art, str):
                    lines.append(f"- {art}")
        note = unfair_ref.get('note', '')
        if note:
            lines.append("")
            for line in str(note).strip().split('\n'):
                lines.append(f"> {line.strip()}")
        lines.append("")
        lines.append("---")
        lines.append("")

    # ì‹¤ì‚¬ì—ì„œ ì œì™¸ (not_covered for DD)
    not_covered_dd = data.get('not_covered', {})
    if isinstance(not_covered_dd, dict) and not_covered_dd.get('title'):
        lines.append(f"## âš ï¸ {not_covered_dd.get('title', 'ë²”ìœ„ ì™¸')}")
        lines.append("")
        for item in not_covered_dd.get('items', []):
            if not isinstance(item, dict):
                continue
            area = item.get('area', '')
            note = item.get('note', '')
            if area:
                lines.append(f"- **{area}**: {note}")
        lines.append("")
        lines.append("---")
        lines.append("")

    # ë©´ì±… ê³ ì§€
    disclaimer = data.get('disclaimer', '')
    if disclaimer:
        lines.append(f"> âš ï¸ **ë©´ì±…**: {disclaimer.strip()}")
    else:
        lines.append("> âš ï¸ **ì°¸ê³ **: ì´ ë¬¸ì„œëŠ” ì¼ë°˜ì ì¸ ì •ë³´ ì œê³µ ëª©ì ì´ë©°,")
        lines.append("> êµ¬ì²´ì ì¸ ë²•ë¥  ë¬¸ì œëŠ” ë³€í˜¸ì‚¬ì™€ ìƒë‹´í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")

    output = "\n".join(lines)

    if output_file:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(output)
        print(f"ì €ì¥ë¨: {output_file}")
    else:
        print(output)

    return data


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë²•ì • ì˜ë¬´ ìº˜ë¦°ë” (Compliance Calendar)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_calendar():
    """ë²•ì • ì˜ë¬´ ìº˜ë¦°ë” YAML ë¡œë“œ"""
    if not CALENDAR_PATH.exists():
        print(f"ERROR: ìº˜ë¦°ë” íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {CALENDAR_PATH}", file=sys.stderr)
        return None

    try:
        with open(CALENDAR_PATH, 'r', encoding='utf-8') as f:
            data = yaml.safe_load(f)
    except yaml.YAMLError as e:
        print(f"ERROR: YAML íŒŒì‹± ì˜¤ë¥˜: {CALENDAR_PATH}", file=sys.stderr)
        print(f"  ìƒì„¸: {e}", file=sys.stderr)
        return None
    except (PermissionError, OSError) as e:
        print(f"ERROR: íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}", file=sys.stderr)
        return None

    if data is None:
        print(f"ERROR: ìº˜ë¦°ë” íŒŒì¼ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤: {CALENDAR_PATH}", file=sys.stderr)
        return None

    return data


def get_upcoming_obligations(days: int = 30, filter_type: str = None):
    """ë‹¤ê°€ì˜¤ëŠ” ë²•ì • ì˜ë¬´ ëª©ë¡ ë°˜í™˜

    Args:
        days: ì•ìœ¼ë¡œ Nì¼ ì´ë‚´ì˜ ì˜ë¬´
        filter_type: í•„í„° (all, listed, large, sme, corp)

    Returns:
        tuple: (list of obligations, skipped_count)
    """
    data = load_calendar()
    if not data:
        return [], 0

    today = datetime.now()
    current_year = today.year
    current_month = today.month

    upcoming = []
    skipped_count = 0

    # ì—°ê°„ ì˜ë¬´ ì²˜ë¦¬
    for item in data.get('annual', []):
        deadline_month = item.get('deadline_month')
        deadline_day = item.get('deadline_day', 1)

        if deadline_month:
            # ì˜¬í•´ ë˜ëŠ” ë‚´ë…„ ê¸°ì¤€ìœ¼ë¡œ ë§ˆê°ì¼ ê³„ì‚°
            try:
                deadline = datetime(current_year, deadline_month, deadline_day)
                if deadline < today:
                    # ì´ë¯¸ ì§€ë‚¬ìœ¼ë©´ ë‚´ë…„ìœ¼ë¡œ
                    deadline = datetime(current_year + 1, deadline_month, deadline_day)
            except ValueError as e:
                print(f"WARNING: ë‚ ì§œ ì˜¤ë¥˜ë¡œ '{item.get('name')}' ê±´ë„ˆëœ€ ({deadline_month}/{deadline_day}): {e}",
                      file=sys.stderr)
                skipped_count += 1
                continue

            days_until = (deadline - today).days
            if 0 <= days_until <= days:
                # í•„í„° ì ìš©
                if filter_type and filter_type != 'all':
                    applies_to = item.get('applies_to', {})
                    company_types = applies_to.get('company_type', ['all'])
                    if filter_type not in company_types and 'all' not in company_types:
                        continue

                upcoming.append({
                    'type': 'annual',
                    'id': item.get('id'),
                    'name': item.get('name'),
                    'description': item.get('description'),
                    'law': item.get('law'),
                    'deadline': deadline.strftime('%Y-%m-%d'),
                    'days_until': days_until,
                    'priority': item.get('priority', 'medium'),
                    'penalty': item.get('penalty'),
                })

    # ë¶„ê¸° ì˜ë¬´ ì²˜ë¦¬ (occurrences ì‚¬ìš©)
    for item in data.get('quarterly', []):
        for occ in item.get('occurrences', []):
            occ_month = occ.get('month')
            occ_day = occ.get('day', 1)

            if occ_month:
                try:
                    deadline = datetime(current_year, occ_month, occ_day)
                    if deadline < today:
                        deadline = datetime(current_year + 1, occ_month, occ_day)
                except ValueError as e:
                    print(f"WARNING: ë‚ ì§œ ì˜¤ë¥˜ë¡œ '{item.get('name')}' ê±´ë„ˆëœ€ ({occ_month}/{occ_day}): {e}",
                          file=sys.stderr)
                    skipped_count += 1
                    continue

                days_until = (deadline - today).days
                if 0 <= days_until <= days:
                    if filter_type and filter_type != 'all':
                        applies_to = item.get('applies_to', {})
                        company_types = applies_to.get('company_type', ['all'])
                        if filter_type not in company_types and 'all' not in company_types:
                            continue

                    upcoming.append({
                        'type': 'quarterly',
                        'id': item.get('id'),
                        'name': f"{item.get('name')} ({occ.get('label', '')})",
                        'description': item.get('description'),
                        'law': item.get('law'),
                        'deadline': deadline.strftime('%Y-%m-%d'),
                        'days_until': days_until,
                        'priority': item.get('priority', 'medium'),
                        'penalty': item.get('penalty'),
                    })

    # ì›”ë³„ ì˜ë¬´ ì²˜ë¦¬
    for item in data.get('monthly', []):
        deadline_day = item.get('deadline_day', 10)

        # ì´ë²ˆ ë‹¬ ë˜ëŠ” ë‹¤ìŒ ë‹¬ (2ì›” ë“± ì§§ì€ ë‹¬ì€ ë§ˆì§€ë§‰ ë‚ ë¡œ ì¡°ì •)
        target_year = current_year
        target_month = current_month

        # í•´ë‹¹ ì›”ì˜ ë§ˆì§€ë§‰ ë‚  í™•ì¸
        last_day_of_month = calendar.monthrange(target_year, target_month)[1]
        actual_day = min(deadline_day, last_day_of_month)
        deadline = datetime(target_year, target_month, actual_day)

        if deadline < today:
            # ì´ë²ˆ ë‹¬ ì§€ë‚¬ìœ¼ë©´ ë‹¤ìŒ ë‹¬
            target_month += 1
            if target_month > 12:
                target_month = 1
                target_year += 1
            last_day_of_month = calendar.monthrange(target_year, target_month)[1]
            actual_day = min(deadline_day, last_day_of_month)
            deadline = datetime(target_year, target_month, actual_day)

        days_until = (deadline - today).days
        if 0 <= days_until <= days:
            if filter_type and filter_type != 'all':
                applies_to = item.get('applies_to', {})
                company_types = applies_to.get('company_type', ['all'])
                if filter_type not in company_types and 'all' not in company_types:
                    continue

            upcoming.append({
                'type': 'monthly',
                'id': item.get('id'),
                'name': item.get('name'),
                'description': item.get('description'),
                'law': item.get('law'),
                'deadline': deadline.strftime('%Y-%m-%d'),
                'days_until': days_until,
                'priority': item.get('priority', 'medium'),
                'penalty': item.get('penalty'),
            })

    # ë§ˆê°ì¼ ìˆœ ì •ë ¬
    upcoming.sort(key=lambda x: x['days_until'])

    return upcoming, skipped_count


def show_calendar(days: int = 30, filter_type: str = None, output_format: str = 'text'):
    """ë²•ì • ì˜ë¬´ ìº˜ë¦°ë” ì¶œë ¥

    Args:
        days: ì•ìœ¼ë¡œ Nì¼ ì´ë‚´ì˜ ì˜ë¬´ í‘œì‹œ
        filter_type: íšŒì‚¬ ìœ í˜• í•„í„°
        output_format: ì¶œë ¥ í˜•ì‹ (text, json)
    """
    data = load_calendar()
    if not data:
        return

    upcoming, skipped_count = get_upcoming_obligations(days, filter_type)

    if output_format == 'json':
        result = {'upcoming': upcoming, 'total': len(upcoming)}
        if skipped_count > 0:
            result['skipped_count'] = skipped_count
        print(json.dumps(result, ensure_ascii=False, indent=2))
        return

    # í—¤ë”
    today_str = datetime.now().strftime('%Y-%m-%d')
    print(f"\nğŸ“… ë²•ì • ì˜ë¬´ ìº˜ë¦°ë” (ê¸°ì¤€ì¼: {today_str})")
    print(f"   ì•ìœ¼ë¡œ {days}ì¼ ë‚´ ë§ˆê° ì˜ë¬´")
    if filter_type:
        print(f"   í•„í„°: {filter_type}")
    print("=" * 60)

    if not upcoming:
        print("\nâœ… í•´ë‹¹ ê¸°ê°„ ë‚´ ë§ˆê° ì˜ë¬´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ìš°ì„ ìˆœìœ„ë³„ ì´ëª¨ì§€
    priority_emoji = {
        'critical': 'ğŸ”´',
        'high': 'ğŸŸ ',
        'medium': 'ğŸŸ¡',
        'low': 'ğŸŸ¢',
    }

    for item in upcoming:
        emoji = priority_emoji.get(item['priority'], 'âšª')
        days_text = f"D-{item['days_until']}" if item['days_until'] > 0 else "ğŸ“¢ ì˜¤ëŠ˜!"

        print(f"\n{emoji} [{days_text}] {item['name']}")
        print(f"   ë§ˆê°: {item['deadline']}")
        print(f"   ê·¼ê±°: {item['law']}")
        if item.get('penalty'):
            print(f"   ë²Œì¹™: {item['penalty']}")

    print("\n" + "=" * 60)
    print(f"ì´ {len(upcoming)}ê±´")

    # ê±´ë„ˆë›´ í•­ëª© ê²½ê³ 
    if skipped_count > 0:
        print(f"\nâš ï¸  WARNING: {skipped_count}ê±´ì˜ ì˜ë¬´ê°€ ë°ì´í„° ì˜¤ë¥˜ë¡œ ê±´ë„ˆë›°ì–´ì¡ŒìŠµë‹ˆë‹¤.", file=sys.stderr)

    # ë©´ì±… ê³ ì§€
    disclaimer = data.get('disclaimer', '')
    if disclaimer:
        print(f"\nâš ï¸  {disclaimer[:100]}...")


def show_calendar_all(output_format: str = 'text'):
    """ì „ì²´ ë²•ì • ì˜ë¬´ ëª©ë¡ ì¶œë ¥"""
    data = load_calendar()
    if not data:
        return

    if output_format == 'json':
        print(json.dumps(data, ensure_ascii=False, indent=2))
        return

    print(f"\nğŸ“… {data.get('name', 'ë²•ì • ì˜ë¬´ ìº˜ë¦°ë”')}")
    print(f"   {data.get('description', '')}")
    print(f"   ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {data.get('last_updated', 'N/A')}")
    print("=" * 60)

    # ì—°ê°„ ì˜ë¬´
    annual = data.get('annual', [])
    if annual:
        print(f"\nğŸ“† ì—°ê°„ ì˜ë¬´ ({len(annual)}ê±´)")
        print("-" * 40)
        for item in annual:
            print(f"  â€¢ {item.get('name')}")
            print(f"    ê¸°í•œ: {item.get('deadline_rule')}")
            print(f"    ê·¼ê±°: {item.get('law')}")

    # ë¶„ê¸° ì˜ë¬´
    quarterly = data.get('quarterly', [])
    if quarterly:
        print(f"\nğŸ“† ë¶„ê¸° ì˜ë¬´ ({len(quarterly)}ê±´)")
        print("-" * 40)
        for item in quarterly:
            print(f"  â€¢ {item.get('name')}")
            print(f"    ê¸°í•œ: {item.get('deadline_rule')}")

    # ì›”ë³„ ì˜ë¬´
    monthly = data.get('monthly', [])
    if monthly:
        print(f"\nğŸ“† ì›”ë³„ ì˜ë¬´ ({len(monthly)}ê±´)")
        print("-" * 40)
        for item in monthly:
            print(f"  â€¢ {item.get('name')}")
            print(f"    ê¸°í•œ: ë§¤ì›” {item.get('deadline_day')}ì¼")

    # ìˆ˜ì‹œ ì˜ë¬´
    event_driven = data.get('event_driven', [])
    if event_driven:
        print(f"\nğŸ“† ìˆ˜ì‹œ ì˜ë¬´ ({len(event_driven)}ê±´)")
        print("-" * 40)
        for item in event_driven:
            print(f"  â€¢ {item.get('name')}")
            print(f"    íŠ¸ë¦¬ê±°: {item.get('trigger')}")
            print(f"    ê¸°í•œ: {item.get('deadline_rule')}")

    total = len(annual) + len(quarterly) + len(monthly) + len(event_driven)
    print(f"\nì´ {total}ê±´")


def main():
    parser = argparse.ArgumentParser(description='Korean Law Fetcher')
    subparsers = parser.add_subparsers(dest='command', help='Commands')

    # search ëª…ë ¹
    search_parser = subparsers.add_parser('search', help='ë²•ë ¹/íŒë¡€ ê²€ìƒ‰')
    search_parser.add_argument('query', help='ê²€ìƒ‰ì–´')
    search_parser.add_argument('--type', default='law',
                               choices=['law', 'prec', 'ordin', 'admrul', 'expc', 'detc'],
                               help='ê²€ìƒ‰ ëŒ€ìƒ (law: ë²•ë ¹, prec: íŒë¡€, ordin: ìì¹˜ë²•ê·œ, admrul: í–‰ì •ê·œì¹™, expc: ë²•ë ¹í•´ì„ë¡€, detc: í—Œì¬ê²°ì •ë¡€)')
    search_parser.add_argument('--display', type=int, default=20, help='ê²°ê³¼ ê°œìˆ˜')
    search_parser.add_argument('--page', type=int, default=1, help='í˜ì´ì§€ ë²ˆí˜¸')
    search_parser.add_argument('--sort', choices=['date', 'name'], help='ì •ë ¬ ê¸°ì¤€ (date: ë‚ ì§œìˆœ, name: ì´ë¦„ìˆœ)')
    search_parser.add_argument('--format', '-f', default='text', choices=['text', 'json'],
                               help='ì¶œë ¥ í˜•ì‹ (text: í…ìŠ¤íŠ¸, json: JSON)')

    # cases ëª…ë ¹ (íŒë¡€ ì „ìš©)
    cases_parser = subparsers.add_parser('cases', help='íŒë¡€ ê²€ìƒ‰')
    cases_parser.add_argument('query', help='ê²€ìƒ‰ì–´')
    cases_parser.add_argument('--court', help='ë²•ì› í•„í„° (ëŒ€ë²•ì›, ê³ ë“±, ì§€ë°©)')
    cases_parser.add_argument('--from', dest='from_date', help='ê²€ìƒ‰ ì‹œì‘ì¼ (YYYYMMDD)')
    cases_parser.add_argument('--display', type=int, default=20, help='ê²°ê³¼ ê°œìˆ˜')
    cases_parser.add_argument('--page', type=int, default=1, help='í˜ì´ì§€ ë²ˆí˜¸')
    cases_parser.add_argument('--format', '-f', default='text', choices=['text', 'json'],
                              help='ì¶œë ¥ í˜•ì‹ (text: í…ìŠ¤íŠ¸, json: JSON)')

    # exact ëª…ë ¹ (ì •í™•í•œ ë²•ë ¹ëª… ê²€ìƒ‰)
    exact_parser = subparsers.add_parser('exact', help='ì •í™•í•œ ë²•ë ¹ëª… ê²€ìƒ‰ (ì˜ˆ: ìƒë²•, ë¯¼ë²•)')
    exact_parser.add_argument('name', help='ì •í™•í•œ ë²•ë ¹ëª…')
    exact_parser.add_argument('--with-admrul', action='store_true',
                              help='ê´€ë ¨ í–‰ì •ê·œì¹™(ê³ ì‹œ/í›ˆë ¹/ì˜ˆê·œ)ë„ í•¨ê»˜ ê²€ìƒ‰')
    exact_parser.add_argument('--format', '-f', default='text', choices=['text', 'json'],
                              help='ì¶œë ¥ í˜•ì‹ (text: í…ìŠ¤íŠ¸, json: JSON)')

    # fetch ëª…ë ¹
    fetch_parser = subparsers.add_parser('fetch', help='ë²•ë ¹/íŒë¡€/í–‰ì •ê·œì¹™ ë‹¤ìš´ë¡œë“œ')
    fetch_parser.add_argument('--id', help='ë²•ë ¹/íŒë¡€/í–‰ì •ê·œì¹™ ID')
    fetch_parser.add_argument('--name', help='ë²•ë ¹ëª…')
    fetch_parser.add_argument('--case', help='íŒë¡€ ì‚¬ê±´ë²ˆí˜¸ (ì˜ˆ: 2022ë‹¤12345)')
    fetch_parser.add_argument('--type', default='law',
                              choices=['law', 'admrul', 'prec', 'ordin', 'expc', 'detc'],
                              help='ë‹¤ìš´ë¡œë“œ ëŒ€ìƒ (law: ë²•ë ¹, admrul: í–‰ì •ê·œì¹™, prec: íŒë¡€ ë“±)')
    fetch_parser.add_argument('--with-decree', action='store_true',
                              help='ì‹œí–‰ë ¹/ì‹œí–‰ê·œì¹™ë„ í•¨ê»˜ ë‹¤ìš´ë¡œë“œ')
    fetch_parser.add_argument('--force', action='store_true',
                              help='ìºì‹œ ë¬´ì‹œí•˜ê³  ê°•ì œ ë‹¤ìš´ë¡œë“œ')

    # recent ëª…ë ¹
    recent_parser = subparsers.add_parser('recent', help='ìµœê·¼ ê°œì • ë²•ë ¹')
    recent_parser.add_argument('--days', type=int, default=30, help='ìµœê·¼ Nì¼')
    recent_parser.add_argument('--from', dest='from_date', help='ì‹œì‘ì¼ (YYYYMMDD)')
    recent_parser.add_argument('--to', dest='to_date', help='ì¢…ë£Œì¼ (YYYYMMDD)')
    recent_parser.add_argument('--date-type', choices=['ef', 'anc'], default='ef',
                               help='ë‚ ì§œ ê¸°ì¤€ (ef: ì‹œí–‰ì¼, anc: ê³µí¬ì¼)')
    recent_parser.add_argument('--format', '-f', default='text', choices=['text', 'json'],
                               help='ì¶œë ¥ í˜•ì‹ (text: í…ìŠ¤íŠ¸, json: JSON)')

    # checklist ëª…ë ¹
    checklist_parser = subparsers.add_parser('checklist', help='ë²•ì  ì²´í¬ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ')
    checklist_subparsers = checklist_parser.add_subparsers(dest='checklist_command', help='ì²´í¬ë¦¬ìŠ¤íŠ¸ ëª…ë ¹')

    # checklist list
    checklist_list_parser = checklist_subparsers.add_parser('list', help='ì‚¬ìš© ê°€ëŠ¥í•œ ì²´í¬ë¦¬ìŠ¤íŠ¸ ëª©ë¡')

    # checklist show
    checklist_show_parser = checklist_subparsers.add_parser('show', help='ì²´í¬ë¦¬ìŠ¤íŠ¸ ì¶œë ¥')
    checklist_show_parser.add_argument('name', help='ì²´í¬ë¦¬ìŠ¤íŠ¸ ì´ë¦„ (ì˜ˆ: startup, privacy_compliance, fair_trade)')
    checklist_show_parser.add_argument('--output', '-o', help='ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (ì˜ˆ: checklist.md)')
    checklist_show_parser.add_argument('--format', '-f', default='markdown', choices=['markdown', 'json'],
                                       help='ì¶œë ¥ í˜•ì‹ (markdown, json)')

    # calendar ëª…ë ¹ (ë²•ì • ì˜ë¬´ ìº˜ë¦°ë”)
    calendar_parser = subparsers.add_parser('calendar', help='ë²•ì • ì˜ë¬´ ìº˜ë¦°ë” ì¡°íšŒ')
    calendar_subparsers = calendar_parser.add_subparsers(dest='calendar_command', help='ìº˜ë¦°ë” ëª…ë ¹')

    # calendar upcoming (ê¸°ë³¸)
    calendar_upcoming_parser = calendar_subparsers.add_parser('upcoming', help='ë‹¤ê°€ì˜¤ëŠ” ë²•ì • ì˜ë¬´')
    calendar_upcoming_parser.add_argument('--days', type=int, default=30, help='ì•ìœ¼ë¡œ Nì¼ ë‚´ (ê¸°ë³¸: 30)')
    calendar_upcoming_parser.add_argument('--filter', dest='filter_type',
                                          choices=['all', 'corp', 'listed', 'large', 'sme'],
                                          help='íšŒì‚¬ ìœ í˜• í•„í„°')
    calendar_upcoming_parser.add_argument('--format', '-f', default='text', choices=['text', 'json'],
                                          help='ì¶œë ¥ í˜•ì‹')

    # calendar list (ì „ì²´ ëª©ë¡)
    calendar_list_parser = calendar_subparsers.add_parser('list', help='ì „ì²´ ë²•ì • ì˜ë¬´ ëª©ë¡')
    calendar_list_parser.add_argument('--format', '-f', default='text', choices=['text', 'json'],
                                      help='ì¶œë ¥ í˜•ì‹')

    args = parser.parse_args()

    if args.command == 'search':
        search_laws(args.query, target=args.type, display=args.display, page=args.page,
                    sort=args.sort, output_format=args.format)
    elif args.command == 'exact':
        search_exact_law(args.name, with_admrul=args.with_admrul, output_format=args.format)
    elif args.command == 'cases':
        search_cases(args.query, court=args.court, from_date=args.from_date,
                     display=args.display, page=args.page, output_format=args.format)
    elif args.command == 'fetch':
        if args.case:
            fetch_case_by_number(args.case)
        elif args.id:
            fetch_law_by_id(args.id, force=args.force, target=args.type)
        elif args.name:
            fetch_law_by_name(args.name, args.with_decree, args.force)
        else:
            print("Error: --id, --name, ë˜ëŠ” --case ì¤‘ í•˜ë‚˜ë¥¼ ì§€ì •í•˜ì„¸ìš”.", file=sys.stderr)
            sys.exit(1)
    elif args.command == 'recent':
        get_recent_laws(args.days, args.from_date, args.to_date, date_type=args.date_type, output_format=args.format)
    elif args.command == 'checklist':
        if args.checklist_command == 'list':
            list_checklists()
        elif args.checklist_command == 'show':
            show_checklist(args.name, output_file=args.output, output_format=args.format)
        else:
            checklist_parser.print_help()
    elif args.command == 'calendar':
        if args.calendar_command == 'upcoming':
            show_calendar(days=args.days, filter_type=args.filter_type, output_format=args.format)
        elif args.calendar_command == 'list':
            show_calendar_all(output_format=args.format)
        else:
            # ê¸°ë³¸: upcoming 30ì¼
            show_calendar(days=30)
    else:
        parser.print_help()


if __name__ == '__main__':
    main()
