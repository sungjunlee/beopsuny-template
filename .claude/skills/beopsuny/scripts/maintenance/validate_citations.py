#!/usr/bin/env python3
"""
ì¡°ë¬¸ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸

YAML íŒŒì¼ì— ì¸ìš©ëœ ë²•ì¡°ë¬¸ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ ê²€ì¦í•©ë‹ˆë‹¤.
ë¶„ê¸°ë³„ ì‹¤í–‰ ê¶Œì¥ (API í˜¸ì¶œ ì œí•œ ê³ ë ¤).

Usage:
    python validate_citations.py              # ì „ì²´ ê²€ì¦ (dry-run)
    python validate_citations.py --sample 10  # ëœë¤ 10ê°œë§Œ ê²€ì¦
    python validate_citations.py --law "ìƒë²•" # íŠ¹ì • ë²•ë ¹ë§Œ ê²€ì¦
    python validate_citations.py --markdown   # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ì¶œë ¥

í™˜ê²½ë³€ìˆ˜:
    BEOPSUNY_OC_CODE: law.go.kr API ì¸ì¦ ì½”ë“œ (í•„ìˆ˜)
"""

import argparse
import json
import os
import random
import re
import sys
import time
import urllib.error
import urllib.parse
import urllib.request
import xml.etree.ElementTree as ET
from pathlib import Path
from typing import Optional, Tuple

import yaml

# ê²½ë¡œ ì„¤ì •
SCRIPT_DIR = Path(__file__).parent
SKILL_DIR = SCRIPT_DIR.parent.parent
ASSETS_DIR = SKILL_DIR / "assets"
CHECKLISTS_DIR = ASSETS_DIR / "checklists"

# API ì„¤ì •
API_BASE_URL = "http://www.law.go.kr/DRF"
ENV_OC_CODE = "BEOPSUNY_OC_CODE"

# ì¡°ë¬¸ ì°¸ì¡° íŒ¨í„´: "ë²•ë ¹ëª… ì œXXì¡°", "ë²•ë ¹ëª… ì œXXì¡°ì˜2 ì œ3í•­"
ARTICLE_PATTERN = re.compile(
    r"([ê°€-í£]+(?:ë²•|ë ¹|ê·œì¹™|ê·œì •))\s*ì œ(\d+)ì¡°(?:ì˜(\d+))?(?:\s*ì œ(\d+)í•­)?"
)


def load_oc_code():
    """OC ì½”ë“œ ë¡œë“œ"""
    oc_code = os.environ.get(ENV_OC_CODE)
    if not oc_code:
        print(f"Error: {ENV_OC_CODE} í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", file=sys.stderr)
        sys.exit(1)
    return oc_code


def load_law_index():
    """law_index.yamlì—ì„œ ë²•ë ¹ ID ë§¤í•‘ ë¡œë“œ"""
    law_index_path = ASSETS_DIR / "law_index.yaml"
    if not law_index_path.exists():
        return {}

    with open(law_index_path, "r", encoding="utf-8") as f:
        data = yaml.safe_load(f) or {}

    return data.get("major_laws", {})


def extract_citations_from_yaml(filepath: Path) -> list:
    """YAML íŒŒì¼ì—ì„œ ì¡°ë¬¸ ì¸ìš© ì¶”ì¶œ"""
    with open(filepath, "r", encoding="utf-8") as f:
        content = f.read()
        data = yaml.safe_load(content) or {}

    citations = []

    # ì •ê·œì‹ìœ¼ë¡œ ëª¨ë“  ì¡°ë¬¸ ì°¸ì¡° ì¶”ì¶œ
    for match in ARTICLE_PATTERN.finditer(content):
        law_name = match.group(1)
        article_num = match.group(2)
        article_sub = match.group(3)  # ì¡°ì˜X
        paragraph = match.group(4)  # ì œXí•­

        citation = {
            "law_name": law_name,
            "article": f"ì œ{article_num}ì¡°" + (f"ì˜{article_sub}" if article_sub else ""),
            "paragraph": f"ì œ{paragraph}í•­" if paragraph else None,
            "full_text": match.group(0),
            "file": str(filepath.relative_to(ASSETS_DIR)),
        }
        citations.append(citation)

    return citations


def collect_all_citations() -> list:
    """ëª¨ë“  YAML íŒŒì¼ì—ì„œ ì¡°ë¬¸ ì¸ìš© ìˆ˜ì§‘"""
    yaml_files = [
        ASSETS_DIR / "compliance_calendar.yaml",
        ASSETS_DIR / "clause_references.yaml",
    ]
    yaml_files.extend(CHECKLISTS_DIR.glob("*.yaml"))

    all_citations = []
    for filepath in yaml_files:
        if filepath.exists():
            citations = extract_citations_from_yaml(filepath)
            all_citations.extend(citations)

    return all_citations


def deduplicate_citations(citations: list) -> list:
    """ì¤‘ë³µ ì œê±° (ë²•ë ¹+ì¡°ë¬¸ ê¸°ì¤€)"""
    seen = set()
    unique = []

    for c in citations:
        key = (c["law_name"], c["article"])
        if key not in seen:
            seen.add(key)
            unique.append(c)

    return unique


def api_request(endpoint: str, params: dict) -> Tuple[Optional[ET.Element], Optional[str]]:
    """law.go.kr API í˜¸ì¶œ

    Returns:
        (XML Element, None) on success
        (None, error_message) on failure
    """
    query = urllib.parse.urlencode(params)
    url = f"{API_BASE_URL}/{endpoint}?{query}"

    try:
        req = urllib.request.Request(url, headers={"User-Agent": "Mozilla/5.0"})
        with urllib.request.urlopen(req, timeout=30) as response:
            content = response.read().decode("utf-8")
            return ET.fromstring(content), None
    except urllib.error.HTTPError as e:
        error_msg = f"HTTP {e.code} {e.reason}"
        print(f"API Error: {error_msg}", file=sys.stderr)
        return None, error_msg
    except urllib.error.URLError as e:
        error_msg = f"Connection failed: {e.reason}"
        print(f"API Error: {error_msg}", file=sys.stderr)
        return None, error_msg
    except ET.ParseError as e:
        error_msg = f"XML parse error: {e}"
        print(f"API Error: {error_msg}", file=sys.stderr)
        return None, error_msg
    except TimeoutError:
        error_msg = "Timeout after 30s"
        print(f"API Error: {error_msg}", file=sys.stderr)
        return None, error_msg


def validate_citation(law_name: str, law_id: str, article: str, oc_code: str) -> dict:
    """ì¡°ë¬¸ ì¡´ì¬ ì—¬ë¶€ ê²€ì¦"""
    params = {
        "OC": oc_code,
        "target": "law",
        "type": "XML",
        "ID": law_id,
    }

    root, error = api_request("lawService.do", params)
    if root is None:
        return {"valid": None, "error": error or "API í˜¸ì¶œ ì‹¤íŒ¨"}

    # ì¡°ë¬¸ ë²ˆí˜¸ ì¶”ì¶œ (ì˜ˆ: "ì œ750ì¡°" â†’ "750")
    article_match = re.match(r"ì œ(\d+)ì¡°(?:ì˜(\d+))?", article)
    if not article_match:
        return {"valid": None, "error": "ì¡°ë¬¸ ë²ˆí˜¸ íŒŒì‹± ì‹¤íŒ¨"}

    target_num = article_match.group(1)
    target_sub = article_match.group(2)

    # ì¡°ë¬¸ ê²€ìƒ‰
    for jo in root.findall(".//ì¡°ë¬¸"):
        jo_num = jo.findtext("ì¡°ë¬¸ë²ˆí˜¸", "")
        jo_content = jo.findtext("ì¡°ë¬¸ë‚´ìš©", "")

        # ì¡°ë¬¸ë²ˆí˜¸ ë§¤ì¹­
        if target_sub:
            # ì œXì¡°ì˜Y í˜•íƒœ
            if f"{target_num}ì¡°ì˜{target_sub}" in jo_num or jo_num == f"{target_num}ì˜{target_sub}":
                return {"valid": True, "jo_content": jo_content[:100]}
        else:
            # ì œXì¡° í˜•íƒœ
            if jo_num == target_num or jo_num.startswith(f"{target_num}ì¡°"):
                return {"valid": True, "jo_content": jo_content[:100]}

    # ì¡°ë¬¸ ëª©ë¡ì´ ì—†ëŠ” ê²½ìš° (API ì‘ë‹µ êµ¬ì¡°ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
    # ì¡°/í•­ ë‹¨ìœ„ ì¡°íšŒê°€ ì•ˆ ë˜ë©´ ë²•ë ¹ ì¡´ì¬ë§Œ í™•ì¸
    law_name_found = root.findtext(".//ë²•ë ¹ëª…_í•œê¸€", "") or root.findtext(".//ë²•ë ¹ëª…", "")
    if law_name_found:
        return {"valid": None, "error": "ì¡°ë¬¸ ë‹¨ìœ„ ê²€ì¦ ë¶ˆê°€ (ë²•ë ¹ì€ ì¡´ì¬)"}

    return {"valid": False, "error": "ì¡°ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ"}


def validate_citations(citations: list, law_index: dict, oc_code: str, delay: float = 0.5) -> list:
    """ì¡°ë¬¸ ëª©ë¡ ê²€ì¦"""
    results = []

    for i, c in enumerate(citations):
        law_name = c["law_name"]

        # ë²•ë ¹ ID ì¡°íšŒ
        law_id = law_index.get(law_name)
        if not law_id:
            results.append({
                **c,
                "valid": None,
                "error": "law_index.yamlì— ì—†ëŠ” ë²•ë ¹",
            })
            continue

        # APIë¡œ ê²€ì¦
        result = validate_citation(law_name, law_id, c["article"], oc_code)
        results.append({**c, **result})

        # API í˜¸ì¶œ ì œí•œ ë°©ì§€
        if i < len(citations) - 1:
            time.sleep(delay)

        # ì§„í–‰ ìƒí™© ì¶œë ¥
        print(f"\rê²€ì¦ ì¤‘: {i + 1}/{len(citations)}", end="", file=sys.stderr)

    print("", file=sys.stderr)
    return results


def format_markdown(results: list) -> str:
    """ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±"""
    invalid = [r for r in results if r.get("valid") is False]
    unknown = [r for r in results if r.get("valid") is None]
    valid = [r for r in results if r.get("valid") is True]

    lines = [
        "## ğŸ“‹ ì¡°ë¬¸ ê²€ì¦ ë¦¬í¬íŠ¸",
        "",
        f"- âœ… ìœ íš¨: {len(valid)}ê°œ",
        f"- â“ í™•ì¸ í•„ìš”: {len(unknown)}ê°œ",
        f"- âŒ ë¬´íš¨: {len(invalid)}ê°œ",
        "",
    ]

    if invalid:
        lines.append("### âŒ ë¬´íš¨ ì¡°ë¬¸ (ì‚­ì œ/ì´ë™ë¨)")
        lines.append("")
        for r in invalid:
            lines.append(f"- `{r['file']}`: {r['full_text']}")
            lines.append(f"  - ì˜¤ë¥˜: {r.get('error', 'N/A')}")
        lines.append("")

    if unknown:
        lines.append("### â“ í™•ì¸ í•„ìš”")
        lines.append("")
        for r in unknown:
            lines.append(f"- `{r['file']}`: {r['full_text']}")
            lines.append(f"  - ì‚¬ìœ : {r.get('error', 'N/A')}")
        lines.append("")

    lines.extend([
        "---",
        f"*ê²€ì¦ì¼: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M')}*",
    ])

    return "\n".join(lines)


def format_text(results: list) -> str:
    """í„°ë¯¸ë„ ì¶œë ¥ìš© í…ìŠ¤íŠ¸"""
    invalid = [r for r in results if r.get("valid") is False]
    unknown = [r for r in results if r.get("valid") is None]
    valid = [r for r in results if r.get("valid") is True]

    lines = [
        "",
        "=== ì¡°ë¬¸ ê²€ì¦ ê²°ê³¼ ===",
        "",
        f"âœ… ìœ íš¨: {len(valid)}ê°œ",
        f"â“ í™•ì¸ í•„ìš”: {len(unknown)}ê°œ",
        f"âŒ ë¬´íš¨: {len(invalid)}ê°œ",
        "",
    ]

    if invalid:
        lines.append("âŒ ë¬´íš¨ ì¡°ë¬¸:")
        for r in invalid:
            lines.append(f"   {r['full_text']} ({r['file']})")
        lines.append("")

    if unknown:
        lines.append("â“ í™•ì¸ í•„ìš”:")
        for r in unknown[:10]:  # ìƒìœ„ 10ê°œë§Œ
            lines.append(f"   {r['full_text']} - {r.get('error', '')}")
        if len(unknown) > 10:
            lines.append(f"   ... ì™¸ {len(unknown) - 10}ê°œ")
        lines.append("")

    return "\n".join(lines)


def main():
    parser = argparse.ArgumentParser(description="ì¡°ë¬¸ ê²€ì¦")
    parser.add_argument("--sample", type=int, help="ëœë¤ Nê°œë§Œ ê²€ì¦")
    parser.add_argument("--law", type=str, help="íŠ¹ì • ë²•ë ¹ë§Œ ê²€ì¦")
    parser.add_argument("--markdown", action="store_true", help="ë§ˆí¬ë‹¤ìš´ ì¶œë ¥")
    parser.add_argument("--json", action="store_true", help="JSON ì¶œë ¥")
    parser.add_argument("--dry-run", action="store_true", help="API í˜¸ì¶œ ì—†ì´ ìˆ˜ì§‘ë§Œ")
    args = parser.parse_args()

    # ì¡°ë¬¸ ìˆ˜ì§‘
    print("ì¡°ë¬¸ ìˆ˜ì§‘ ì¤‘...", file=sys.stderr)
    citations = collect_all_citations()
    citations = deduplicate_citations(citations)

    # í•„í„°ë§
    if args.law:
        citations = [c for c in citations if args.law in c["law_name"]]

    if args.sample and args.sample < len(citations):
        citations = random.sample(citations, args.sample)

    print(f"ì´ {len(citations)}ê°œ ì¡°ë¬¸ ë°œê²¬", file=sys.stderr)

    if args.dry_run:
        # API í˜¸ì¶œ ì—†ì´ ìˆ˜ì§‘ ê²°ê³¼ë§Œ ì¶œë ¥
        if args.json:
            print(json.dumps(citations, ensure_ascii=False, indent=2))
        else:
            for c in citations[:20]:
                print(f"  {c['law_name']} {c['article']} ({c['file']})")
            if len(citations) > 20:
                print(f"  ... ì™¸ {len(citations) - 20}ê°œ")
        return

    # OC ì½”ë“œ ë¡œë“œ
    oc_code = load_oc_code()
    law_index = load_law_index()

    # ê²€ì¦ ì‹¤í–‰
    results = validate_citations(citations, law_index, oc_code)

    # ì¶œë ¥
    if args.json:
        print(json.dumps(results, ensure_ascii=False, indent=2))
    elif args.markdown:
        print(format_markdown(results))
    else:
        print(format_text(results))

    # ì¢…ë£Œ ì½”ë“œ: ë¬´íš¨ ì¡°ë¬¸ì´ ìˆìœ¼ë©´ 1
    invalid_count = len([r for r in results if r.get("valid") is False])
    sys.exit(1 if invalid_count > 0 else 0)


if __name__ == "__main__":
    main()
